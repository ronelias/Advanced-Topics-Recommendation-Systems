{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f07f204d-b129-41bb-ad9d-e52b522c8148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nbimporter\n",
      "  Downloading nbimporter-0.3.4-py3-none-any.whl.metadata (252 bytes)\n",
      "Downloading nbimporter-0.3.4-py3-none-any.whl (4.9 kB)\n",
      "Installing collected packages: nbimporter\n",
      "Successfully installed nbimporter-0.3.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install nbimporter\n",
    "!pip install ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f86f3f90-9c78-42fa-8bd8-e83c1a7a01d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import nbimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f654d898-ee78-4a04-888e-4560dca4e0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import architectures\n",
    "from recommenders_architecture import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b25565-a06b-4827-a30d-b4fb1aea74c4",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10fe0bfc-9192-4912-a6d7-f679269adca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= Load Pairwise Training Data =======\n",
    "current_dir = Path.cwd()\n",
    "\n",
    "pairwise_data_path= current_dir.parent / \"data\" / \"pairwise\"/\"pairwise_training_data_no_timestamp.csv\"\n",
    "df = pd.read_csv(pairwise_data_path)\n",
    "\n",
    "# ======= Load Item Metadata (1027-dim vectors) =======\n",
    "models_dir = current_dir.parent / \"models\" \n",
    "encoded_dir = current_dir.parent / \"data\" / \"encoded\"\n",
    "encoded_text_file = encoded_dir / \"embedding_dict_with_price_longformer_idx.pt\"\n",
    "encoded_images_file = encoded_dir / \"images_encodings.pkl\"\n",
    "encoded_metadata_text_image_file = encoded_dir / \"item_metadata_text_image.pt\"\n",
    "auto_encoder_metadata_file = encoded_dir / \"compressed_all_data_encodings_256.pkl\"\n",
    "user_embed_model_path = models_dir / \"Yahlly_Optuna_23_2_MFBiases_0_0.9449033475350068.pth\"\n",
    "text_embeddings = torch.load(encoded_text_file)\n",
    "\n",
    "with open(encoded_images_file, 'rb') as f:\n",
    "    images_embeddings = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e615d33e-004d-4865-9a39-9a67ed9e05b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ======= Configurations =======\n",
    "EMBEDDING_DIM = 24  # User embedding size\n",
    "ITEM_FEATURE_DIM = 3075# item_metadata[0].shape # Length of item metadata vector (text+image)\n",
    "#ITEM_FEATURE_DIM = 256 # After autoencoder\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 10\n",
    "LR = 0.00001  # Learning rate\n",
    "VAL_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5becac4-7be8-43c3-9cf4-d3213727da42",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a136900f-23aa-4b6a-8480-548442e840fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### if we choose to use Auto encoder data instead of the long text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df95d1de-f2c1-4ce4-a80d-a4394052ec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(auto_encoder_metadata_file, 'rb') as f:\n",
    "#     item_metadata = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9286931c-b1be-4d6c-a37a-e823b87746c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# item_embeddings_tensor = torch.zeros(len(item_metadata), item_metadata[0].size(0))\n",
    "# for idx, (item_id, embed) in enumerate(item_metadata.items()):\n",
    "#     item_embeddings_tensor[idx] = embed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "62226822-cf96-4ad8-89ee-acb3dd7c5d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto_encoder_metadata_file_pt_out = encoded_dir / \"compressed_all_data_encodings_256.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bc08fe23-2333-40a1-a3dd-7ad519c0d3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(item_embeddings_tensor,auto_encoder_metadata_file_pt_out )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7b93a1-3f76-4d61-9fce-7b8781928917",
   "metadata": {},
   "source": [
    "### Load pretrained embeddings from MF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d488209-682d-4f93-8a30-81097c42ce7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_file_path = current_dir.parent / \"data\" / \"data_and_test_files\" / \"user_item_rating_table_train_with_idx.csv\"\n",
    "df2 = pd.read_csv(user_item_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f507d9c-06f1-4e57-9dd4-83bcff78b04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MFWithBiasesFreeze(\n",
       "  (user_bias): Embedding(1096901, 1)\n",
       "  (item_bias): Embedding(198771, 1)\n",
       "  (user_embedding): Embedding(1096901, 24)\n",
       "  (item_embedding): Embedding(198771, 24)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = current_dir.parent / \"models\" / \"Yahlly_24_2_MF_Frozen_Biases_18_0.934416908145054.pth\"\n",
    "\n",
    "model = torch.load(model_path, map_location=device)  # Load the entire model object\n",
    "model.eval()  # Set to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9d35b5d-cbef-48d5-a6c5-2e7046983827",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_user_embed = model.user_embedding\n",
    "initial_item_embed = model.item_embedding\n",
    "initial_user_bias = model.user_bias\n",
    "initial_item_bias = model.item_bias\n",
    "initial_global_bias = model.global_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3d87aca-6dd9-490b-9cf0-8c929d1a2d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(198771, 24)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_item_embed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848e1456-7c08-44c6-8e9f-96c999a7d4e2",
   "metadata": {},
   "source": [
    "### Concat image and text embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a96374-caa6-44ec-9591-47e133ce9aac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Create concat of image and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b2cf0177-1837-4da8-b037-230bddb2c2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Item metadata saved to /storage/yahlly/RecSys/data/encoded/item_metadata_text_image.pt with 198771 items.\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "\n",
    "# # ======= Create Combined Item Metadata =======\n",
    "# item_metadata = {}\n",
    "\n",
    "# for item_id in text_embeddings.keys():\n",
    "#     text_embed = text_embeddings[item_id]  # (1027,)\n",
    "#     image_embed = images_embeddings.get(item_id, torch.zeros(2048))  # (2048,) default to zeros if missing\n",
    "\n",
    "#     # Concatenate along the feature dimension\n",
    "#     combined_embed = torch.cat([text_embed, image_embed], dim=0)  # (3075,)\n",
    "#     item_metadata[item_id] = combined_embed\n",
    "\n",
    "# # Save the combined metadata dictionary\n",
    "# metadata_save_path = encoded_dir / \"item_metadata_text_image.pt\"\n",
    "# torch.save(item_metadata, metadata_save_path)\n",
    "\n",
    "# print(f\"✅ Item metadata saved to {metadata_save_path} with {len(item_metadata)} items.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d167131-47a3-4bb5-bc75-bab0d0686a80",
   "metadata": {},
   "source": [
    "### Load item_metadata (text+image embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbe7c3c8-cf25-417f-bee2-2c5f03a87b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_metadata = torch.load( encoded_dir / \"item_metadata_text_image.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1806ef-d70d-44a2-9f9c-4e0349668034",
   "metadata": {},
   "source": [
    "#### make the item metadata a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3704363-e0a7-4106-931b-93dd5d8d176f",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_embeddings_tensor = torch.zeros(len(item_metadata), item_metadata[0].size(0))\n",
    "for idx, (item_id, embed) in enumerate(item_metadata.items()):\n",
    "    item_embeddings_tensor[idx] = embed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "903e3d7b-a612-4e95-aec4-cea73a6ff0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_embeddings_tensor=item_embeddings_tensor.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabf8da5-eb2c-4aa4-8ee3-61f05560e03e",
   "metadata": {},
   "source": [
    "### Data loader class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cca433a-b985-45f9-b76e-82c9b748d10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= Custom Dataset Class =======\n",
    "class PairwiseDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.users = dataframe[\"user_id\"].values\n",
    "        self.item1 = dataframe[\"item1_id\"].values\n",
    "        self.item2 = dataframe[\"item2_id\"].values\n",
    "        self.labels = dataframe[\"label\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            self.users[idx],\n",
    "            self.item1[idx],\n",
    "            self.item2[idx],\n",
    "            self.labels[idx],\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df56404e-6d20-4ed8-ba55-83f84846a096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= Two-Tower Model (User & Item Networks) =======\n",
    "class TwoTowerModelPretrainedUserEmbeddings(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, item_metadata_dim):\n",
    "        super(TwoTowerModel, self).__init__()\n",
    "        \n",
    "        # User Tower (Embedding)\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim) \n",
    "        ### LOAD PRETRAINED USER EMBEDDINGS\n",
    "        self.user_embedding.weight.data.copy_(initial_user_embed.weight.data)\n",
    "\n",
    "        \n",
    "        # Item Tower (Using Item Metadata)\n",
    "        self.item_fc = nn.Sequential(\n",
    "            nn.Linear(item_metadata_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, embedding_dim),\n",
    "        )\n",
    "    \n",
    "    def forward(self, user_ids, item1_ids, item2_ids):\n",
    "        item1_ids=item1_ids.to(device)\n",
    "        item2_ids=item2_ids.to(device)\n",
    "        user_embed = self.user_embedding(user_ids)  # (batch, embedding_dim)\n",
    "        item1_embed = self.item_fc(item_embeddings_tensor[item1_ids])  # (batch, embedding_dim)\n",
    "        item2_embed = self.item_fc(item_embeddings_tensor[item2_ids])  # (batch, embedding_dim)\n",
    "        \n",
    "        return user_embed, item1_embed, item2_embed\n",
    "\n",
    "# ======= Pairwise BPR Loss =======\n",
    "\n",
    "\n",
    "class BPRLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BPRLoss, self).__init__()\n",
    "\n",
    "    def forward(self, user_embed, item1_ids, item1_embed, item2_ids, item2_embed, labels):\n",
    "        \"\"\"\n",
    "        Compute Bayesian Personalized Ranking (BPR) loss.\n",
    "\n",
    "        Args:\n",
    "        - user_embed: Tensor of shape (batch_size, embed_dim), user embeddings.\n",
    "        - item1_ids: Tensor of shape (batch_size,), IDs of item1.\n",
    "        - item1_embed: Tensor of shape (batch_size, embed_dim), embeddings for item1.\n",
    "        - item2_ids: Tensor of shape (batch_size,), IDs of item2.\n",
    "        - item2_embed: Tensor of shape (batch_size, embed_dim), embeddings for item2.\n",
    "        - labels: Tensor of shape (batch_size,), IDs of the correct (positive) item.\n",
    "\n",
    "        Returns:\n",
    "        - loss: Computed BPR loss.\n",
    "        \"\"\"\n",
    "        # Convert labels to binary: 1 if item1 is the positive item, else 0\n",
    "        labels_binary = (labels == item1_ids).float()\n",
    "\n",
    "        # Compute scores\n",
    "        score1 = (user_embed * item1_embed).sum(dim=1)  # Affinity score for item1\n",
    "        score2 = (user_embed * item2_embed).sum(dim=1)  # Affinity score for item2\n",
    "\n",
    "        # Assign correct positive and negative scores based on labels_binary\n",
    "        pos_score = torch.where(labels_binary == 1, score1, score2)\n",
    "        neg_score = torch.where(labels_binary == 1, score2, score1)\n",
    "\n",
    "        # Compute BPR loss\n",
    "        loss = -torch.log(torch.sigmoid(pos_score - neg_score)).mean()\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a6aa6ff-cc02-4bd8-8e6e-71c245517045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item1_id</th>\n",
       "      <th>item2_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>50787</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33482</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>35983</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>125581</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>60296</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item1_id  item2_id  label\n",
       "0        0     50787         0      0\n",
       "1        0         1     33482      1\n",
       "2        0     35983         2      2\n",
       "3        0         3    125581      3\n",
       "4        0         4     60296      4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0102ea4-3720-46ed-88b5-ce2759ca2f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = int(len(df) * VAL_SPLIT)\n",
    "train_df, val_df = df[:-val_size], df[-val_size:] #df[:-val_size], df[-val_size:]\n",
    "# ======= Dataloaders =======\n",
    "train_loader = DataLoader(PairwiseDataset(train_df), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(PairwiseDataset(val_df), batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80bc30b8-dbc6-4e8f-a963-a10ab0a3b616",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = 1096901\n",
    "num_items = 198771\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f32256eb-7757-4659-8897-10d536899224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Training Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 16045/16045 [01:24<00:00, 189.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6932,Val Loss = 0.6932, Val Accuracy = 0.4996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 16045/16045 [01:24<00:00, 190.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss = 0.6918,Val Loss = 0.6937, Val Accuracy = 0.4993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 16045/16045 [01:23<00:00, 192.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss = 0.6824,Val Loss = 0.6992, Val Accuracy = 0.4993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 16045/16045 [01:24<00:00, 189.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss = 0.6592,Val Loss = 0.7113, Val Accuracy = 0.4992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 16045/16045 [01:24<00:00, 189.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss = 0.6278,Val Loss = 0.7233, Val Accuracy = 0.4992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 16045/16045 [01:24<00:00, 190.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss = 0.5960,Val Loss = 0.7331, Val Accuracy = 0.4989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 16045/16045 [01:23<00:00, 192.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss = 0.5661,Val Loss = 0.7404, Val Accuracy = 0.4990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 16045/16045 [01:23<00:00, 191.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss = 0.5382,Val Loss = 0.7466, Val Accuracy = 0.4990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 16045/16045 [01:23<00:00, 192.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss = 0.5124,Val Loss = 0.7516, Val Accuracy = 0.4991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 16045/16045 [01:24<00:00, 190.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss = 0.4884,Val Loss = 0.7556, Val Accuracy = 0.4989\n",
      "✅ Model Training Complete!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ======= Initialize Model, Loss, Optimizer =======\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TwoTowerModelPretrainedUserEmbeddings(num_users, num_items, EMBEDDING_DIM, ITEM_FEATURE_DIM).to(device)\n",
    "criterion = BPRLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# ======= Training Loop =======\n",
    "# ======= Training & Validation =======\n",
    "log_file = \"cold_training_log.txt\"\n",
    "\n",
    "print(\"🚀 Training Model...\")\n",
    "with open(log_file, \"w\") as log:\n",
    "    log.write(\"🚀 Training Model...\\n\")\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "    \n",
    "        for user_ids, item1_ids, item2_ids,labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "            user_ids, item1_ids, item2_ids,labels = user_ids.to(device), item1_ids.to(device), item2_ids.to(device), labels.to(device)\n",
    "    \n",
    "            # Forward Pass\n",
    "            user_embed, item1_embed, item2_embed = model(user_ids, item1_ids, item2_ids)\n",
    "            #print(item1_embed==item2_embed)\n",
    "            # Compute Loss\n",
    "            # print(item1_embed==item2_embed)\n",
    "            loss = criterion(user_embed,item1_ids, item1_embed,item2_ids, item2_embed, labels)\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_loss = train_loss /len(train_loader)\n",
    "        # ======= Validation =======\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        val_loss = 0\n",
    "        for user_ids, item1_ids, item2_ids, labels in val_loader:\n",
    "            user_ids, item1_ids, item2_ids, labels = (\n",
    "                user_ids.to(device),\n",
    "                item1_ids.to(device),\n",
    "                item2_ids.to(device),\n",
    "                labels.to(device),\n",
    "            )\n",
    "            user_embed, item1_embed, item2_embed = model(user_ids, item1_ids, item2_ids)\n",
    "            #print((item1_embed==item2_embed).all())\n",
    "            score1 = (user_embed * item1_embed).sum(dim=1)  # Score for item1\n",
    "            score2 = (user_embed * item2_embed).sum(dim=1)  # Score for item2\n",
    "    \n",
    "            # Determine the correct positive and negative scores based on labels\n",
    "            labels_binary = (labels == item1_ids).float()\n",
    "            #print(labels_binary)\n",
    "            pos_scores = torch.where(labels_binary == 1, score1, score2)\n",
    "            neg_scores = torch.where(labels_binary == 1, score2, score1)\n",
    "            #print(pos_scores)\n",
    "            # Check if the model correctly ranked the positive item higher\n",
    "            loss = criterion(user_embed,item1_ids, item1_embed,item2_ids, item2_embed, labels)\n",
    "            val_loss += loss.item()\n",
    "            predictions = pos_scores > neg_scores\n",
    "    \n",
    "            correct += predictions.sum().item()\n",
    "            total += predictions.shape[0]\n",
    "    \n",
    "        val_accuracy = correct / total\n",
    "        val_loss=val_loss/len(val_loader)\n",
    "        print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f},Val Loss = {val_loss:.4f}, Val Accuracy = {val_accuracy:.4f}\")\n",
    "        log.write(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}, Val Accuracy = {val_accuracy:.4f}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# ======= Save Model =======\n",
    "#torch.save(model.state_dict(), \"trained_model.pth\")\n",
    "print(\"✅ Model Training Complete!\")\n",
    "with open(log_file, \"a\") as log:\n",
    "    log.write(\"✅ Model Training Complete!\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
