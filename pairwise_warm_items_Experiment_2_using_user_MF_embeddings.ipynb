{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b02e711-4121-4a40-8023-6b256c7a3564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nbimporter\n",
      "  Downloading nbimporter-0.3.4-py3-none-any.whl.metadata (252 bytes)\n",
      "Downloading nbimporter-0.3.4-py3-none-any.whl (4.9 kB)\n",
      "Installing collected packages: nbimporter\n",
      "Successfully installed nbimporter-0.3.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install nbimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6e12146-a425-4988-9105-a276734b5711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipynb\n",
      "  Downloading ipynb-0.5.1-py3-none-any.whl.metadata (303 bytes)\n",
      "Downloading ipynb-0.5.1-py3-none-any.whl (6.9 kB)\n",
      "Installing collected packages: ipynb\n",
      "Successfully installed ipynb-0.5.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f86f3f90-9c78-42fa-8bd8-e83c1a7a01d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7d473ba-1f55-440d-aafb-466a8b74ebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eeb2f1f-8f8e-4307-91a8-4e91e163dec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4bb10ab-fd9d-4cf6-8a66-1ba4671c7803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import architectures\n",
    "from recommenders_architecture import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b25565-a06b-4827-a30d-b4fb1aea74c4",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "10fe0bfc-9192-4912-a6d7-f679269adca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= Load Pairwise Training Data =======\n",
    "current_dir = Path.cwd()\n",
    "\n",
    "pairwise_data_path= current_dir.parent / \"data\" / \"pairwise\"/\"pairwise_data.csv\"\n",
    "df = pd.read_csv(pairwise_data_path)\n",
    "pairwise_data_train_path= current_dir.parent / \"data\" / \"pairwise\"/\"pairwise_train.csv\"\n",
    "train = pd.read_csv(pairwise_data_train_path)\n",
    "pairwise_data_val_path= current_dir.parent / \"data\" / \"pairwise\"/\"pairwise_val.csv\"\n",
    "val = pd.read_csv(pairwise_data_val_path)\n",
    "# ======= Load Item Metadata (1027-dim vectors) =======\n",
    "encoded_dir = current_dir.parent / \"data\" / \"encoded\"\n",
    "encoded_text_file = encoded_dir / \"embedding_dict_with_price_longformer_idx.pt\"\n",
    "encoded_images_file = encoded_dir / \"images_encodings.pkl\"\n",
    "encoded_metadata_text_image_file = encoded_dir / \"item_metadata_text_image.pt\"\n",
    "text_embeddings = torch.load(encoded_text_file)\n",
    "\n",
    "with open(encoded_images_file, 'rb') as f:\n",
    "    images_embeddings = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f746a89b-1e6c-4deb-a9e3-1bdc59cc245b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1027])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_embeddings[131488].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e101ac71-a333-4709-9bd6-6e7b99e0bdac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_embeddings[90788].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4614b1d7-7941-4e9e-996e-bb8150468414",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcf48745-f6fe-4593-b114-372863344518",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_file_path = current_dir.parent / \"data\" / \"data_and_test_files\" / \"user_item_rating_table_train_with_idx.csv\"\n",
    "df2 = pd.read_csv(user_item_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "257cf710-f598-4478-856e-3f7f08f0e261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MFWithBiasesFreeze(\n",
       "  (user_bias): Embedding(1096901, 1)\n",
       "  (item_bias): Embedding(198771, 1)\n",
       "  (user_embedding): Embedding(1096901, 24)\n",
       "  (item_embedding): Embedding(198771, 24)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = current_dir.parent / \"models\" / \"Yahlly_24_2_MF_Frozen_Biases_18_0.934416908145054.pth\"\n",
    "\n",
    "model = torch.load(model_path, map_location=device)  # Load the entire model object\n",
    "model.eval()  # Set to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c046afcb-82d7-4724-9bdb-1621a4016891",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_user_embed = model.user_embedding\n",
    "initial_item_embed = model.item_embedding\n",
    "initial_user_bias = model.user_bias\n",
    "initial_item_bias = model.item_bias\n",
    "initial_global_bias = model.global_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4405b37-0406-45a9-8e77-e6e7b53c2fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_encoder_metadata_file= encoded_dir / \"compressed_all_data_encodings_256.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf305d5f-b4df-442d-81cf-c30dcb77dc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_metadata = torch.load( auto_encoder_metadata_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d83c955-710e-4b04-bee1-d6b389fc34b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item1_id</th>\n",
       "      <th>item2_id</th>\n",
       "      <th>label</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13349</td>\n",
       "      <td>0</td>\n",
       "      <td>1349041740000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>22959</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1370958618000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>97562</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1440038761000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>23003</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1483320893000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>16177</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1490800837000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9127372</th>\n",
       "      <td>1096899</td>\n",
       "      <td>45300</td>\n",
       "      <td>92761</td>\n",
       "      <td>92761</td>\n",
       "      <td>1692552496934</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9127373</th>\n",
       "      <td>1096900</td>\n",
       "      <td>183765</td>\n",
       "      <td>86867</td>\n",
       "      <td>183765</td>\n",
       "      <td>1600792118191</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9127374</th>\n",
       "      <td>1096900</td>\n",
       "      <td>155119</td>\n",
       "      <td>99585</td>\n",
       "      <td>155119</td>\n",
       "      <td>1615811081145</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9127375</th>\n",
       "      <td>1096900</td>\n",
       "      <td>25515</td>\n",
       "      <td>75800</td>\n",
       "      <td>25515</td>\n",
       "      <td>1693494834857</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9127376</th>\n",
       "      <td>1096900</td>\n",
       "      <td>44042</td>\n",
       "      <td>76857</td>\n",
       "      <td>76857</td>\n",
       "      <td>1694098256216</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9127377 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  item1_id  item2_id   label      timestamp  rating\n",
       "0              0         0     13349       0  1349041740000     5.0\n",
       "1              0     22959         1       1  1370958618000     1.0\n",
       "2              0     97562         2       2  1440038761000     5.0\n",
       "3              0     23003         3       3  1483320893000     3.0\n",
       "4              0     16177         4       4  1490800837000     5.0\n",
       "...          ...       ...       ...     ...            ...     ...\n",
       "9127372  1096899     45300     92761   92761  1692552496934     5.0\n",
       "9127373  1096900    183765     86867  183765  1600792118191     1.0\n",
       "9127374  1096900    155119     99585  155119  1615811081145     1.0\n",
       "9127375  1096900     25515     75800   25515  1693494834857     4.0\n",
       "9127376  1096900     44042     76857   76857  1694098256216     5.0\n",
       "\n",
       "[9127377 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848e1456-7c08-44c6-8e9f-96c999a7d4e2",
   "metadata": {},
   "source": [
    "### Concat image and text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2cf0177-1837-4da8-b037-230bddb2c2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_982/2002973043.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  images_embeddings = {k: torch.tensor(v) for k, v in images_embeddings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Item metadata saved to /storage/yahlly/RecSys/data/encoded/item_metadata_text_image.pt with shape torch.Size([198771, 3075])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# ======= Create Combined Item Metadata =======\n",
    "item_metadata = {}\n",
    "\n",
    "for item_id in text_embeddings.keys():\n",
    "    text_embed = text_embeddings[item_id]  # (1027,)\n",
    "    image_embed = images_embeddings.get(item_id, torch.zeros(2048))  # (2048,) default to zeros if missing\n",
    "\n",
    "    # Concatenate along the feature dimension\n",
    "    combined_embed = torch.cat([text_embed, image_embed], dim=0)  # (3075,)\n",
    "    item_metadata[item_id] = combined_embed\n",
    "\n",
    "# Save the combined metadata dictionary\n",
    "metadata_save_path = encoded_dir / \"item_metadata_text_image.pt\"\n",
    "torch.save(item_metadata, metadata_save_path)\n",
    "\n",
    "print(f\"✅ Item metadata saved to {metadata_save_path} with {len(item_metadata)} items.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75ad1d21-915a-4838-bb75-cc102dd756f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_metadata[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d167131-47a3-4bb5-bc75-bab0d0686a80",
   "metadata": {},
   "source": [
    "### Load item_metadata (text+image embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbe7c3c8-cf25-417f-bee2-2c5f03a87b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_metadata = torch.load(encoded_text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a285a9a1-4f4e-4610-bfc0-d79e592c532f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mitem_metadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "item_metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e615d33e-004d-4865-9a39-9a67ed9e05b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # ======= Configurations =======\n",
    "# EMBEDDING_DIM = 128  # User embedding size\n",
    "# ITEM_FEATURE_DIM = item_metadata[0].shape # Length of item metadata vector (text+image)\n",
    "# BATCH_SIZE = 512\n",
    "# EPOCHS = 10\n",
    "# LR = 0.0001  # Learning rate\n",
    "# VAL_SPLIT = 0.1\n",
    "\n",
    "\n",
    "# ======= Configurations =======\n",
    "EMBEDDING_DIM = 24  # User embedding size\n",
    "#ITEM_FEATURE_DIM = 3075# item_metadata[0].shape # Length of item metadata vector (text+image)\n",
    "ITEM_FEATURE_DIM = 256 # After autoencoder\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 10\n",
    "LR = 0.00001  # Learning rate\n",
    "VAL_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3cca433a-b985-45f9-b76e-82c9b748d10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= Custom Dataset Class =======\n",
    "class PairwiseDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.users = dataframe[\"user_id\"].values\n",
    "        self.item1 = dataframe[\"item1_id\"].values\n",
    "        self.item2 = dataframe[\"item2_id\"].values\n",
    "        self.labels = dataframe[\"label\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            self.users[idx],\n",
    "            self.item1[idx],\n",
    "            self.item2[idx],\n",
    "            self.labels[idx],\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "15d563bb-4804-4ed6-bbe7-cc76f520d18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_metadata=item_metadata.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df56404e-6d20-4ed8-ba55-83f84846a096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= Two-Tower Model (User & Item Networks) =======\n",
    "\n",
    "class TwoTowerModelPrevEmbedInit(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, item_metadata_dim):\n",
    "        super(TwoTowerModel, self).__init__()\n",
    "        \n",
    "        # User Tower (Embedding)\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)  # LOAD PRETRAINED USER EMBEDDINGS\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)  # LOAD PRETRAINED ITEM EMBEDDINGS\n",
    "        self.user_embedding.weight.data.copy_(initial_user_embed.weight.data)\n",
    "        self.item_embedding.weight.data.copy_(initial_item_embed.weight.data)\n",
    "        # Item Tower (Using Item Metadata)\n",
    "        self.item_fc = nn.Sequential(\n",
    "            nn.Linear(item_metadata_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, embedding_dim),\n",
    "        )\n",
    "\n",
    "        # Second-Level Item Embedding Combination\n",
    "        self.item_fc2 = nn.Sequential(\n",
    "            nn.Linear(2 * embedding_dim, 512),  # Concatenating two embedding sources\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, embedding_dim),\n",
    "        )\n",
    "    \n",
    "    def forward(self, user_ids, item1_ids, item2_ids):\n",
    "        # User embedding\n",
    "        user_ids=user_ids.to(device)\n",
    "        item1_ids=item1_ids.to(device)\n",
    "        item2_ids=item2_ids.to(device)\n",
    "        user_embed = self.user_embedding(user_ids)  # (batch, embedding_dim)\n",
    "\n",
    "        # Item metadata-based embedding\n",
    "        item1_meta_embed = self.item_fc(item_metadata[item1_ids])  # (batch, embedding_dim)\n",
    "        item2_meta_embed = self.item_fc(item_metadata[item2_ids])  # (batch, embedding_dim)\n",
    "\n",
    "        # Item ID-based embedding (pretrained)\n",
    "        item1_id_embed = self.item_embedding(item1_ids)  # (batch, embedding_dim)\n",
    "        item2_id_embed = self.item_embedding(item2_ids)  # (batch, embedding_dim)\n",
    "\n",
    "        # Concatenate metadata-based and ID-based embeddings\n",
    "        item1_combined = torch.cat([item1_meta_embed, item1_id_embed], dim=1)  # (batch, 2*embedding_dim)\n",
    "        item2_combined = torch.cat([item2_meta_embed, item2_id_embed], dim=1)  # (batch, 2*embedding_dim)\n",
    "\n",
    "        # Second-Level Representation Learning\n",
    "        item1_embed_level2 = self.item_fc2(item1_combined)  # (batch, embedding_dim)\n",
    "        item2_embed_level2 = self.item_fc2(item2_combined)  # (batch, embedding_dim)\n",
    "\n",
    "        return user_embed, item1_embed_level2, item2_embed_level2\n",
    "\n",
    "\n",
    "\n",
    "class BPRLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BPRLoss, self).__init__()\n",
    "\n",
    "    def forward(self, user_embed, item1_ids, item1_embed, item2_ids, item2_embed, labels):\n",
    "        \"\"\"\n",
    "        Compute Bayesian Personalized Ranking (BPR) loss.\n",
    "\n",
    "        Args:\n",
    "        - user_embed: Tensor of shape (batch_size, embed_dim), user embeddings.\n",
    "        - item1_ids: Tensor of shape (batch_size,), IDs of item1.\n",
    "        - item1_embed: Tensor of shape (batch_size, embed_dim), embeddings for item1.\n",
    "        - item2_ids: Tensor of shape (batch_size,), IDs of item2.\n",
    "        - item2_embed: Tensor of shape (batch_size, embed_dim), embeddings for item2.\n",
    "        - labels: Tensor of shape (batch_size,), IDs of the correct (positive) item.\n",
    "\n",
    "        Returns:\n",
    "        - loss: Computed BPR loss.\n",
    "        \"\"\"\n",
    "        # Convert labels to binary: 1 if item1 is the positive item, else 0\n",
    "        labels_binary = (labels == item1_ids).float()\n",
    "\n",
    "        # Compute scores\n",
    "        score1 = (user_embed * item1_embed).sum(dim=1)  # Affinity score for item1\n",
    "        score2 = (user_embed * item2_embed).sum(dim=1)  # Affinity score for item2\n",
    "\n",
    "        # Assign correct positive and negative scores based on labels_binary\n",
    "        pos_score = torch.where(labels_binary == 1, score1, score2)\n",
    "        neg_score = torch.where(labels_binary == 1, score2, score1)\n",
    "\n",
    "        # Compute BPR loss\n",
    "        loss = -torch.log(torch.sigmoid(pos_score - neg_score)).mean()\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b9f8ee3-487c-4e1b-bfd5-83ba3babf5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### MODEL WITH BIASES\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# class TwoTowerModel(nn.Module):\n",
    "#     def __init__(self, num_users, num_items, embedding_dim, item_metadata_dim):\n",
    "#         super(TwoTowerModel, self).__init__()\n",
    "        \n",
    "#         # User Tower (Embedding)\n",
    "#         self.user_embedding = nn.Embedding(num_users, embedding_dim)  # LOAD PRETRAINED USER EMBEDDINGS\n",
    "#         self.item_embedding = nn.Embedding(num_items, embedding_dim)  # LOAD PRETRAINED ITEM EMBEDDINGS\n",
    "\n",
    "#         # Bias terms\n",
    "#         self.user_bias = nn.Embedding(num_users, 1)  # Bias for each user\n",
    "#         self.item_bias = nn.Embedding(num_items, 1)  # Bias for each item\n",
    "\n",
    "#         # Item Tower (Using Item Metadata)\n",
    "#         self.item_fc = nn.Sequential(\n",
    "#             nn.Linear(item_metadata_dim, 512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(512, embedding_dim),\n",
    "#         )\n",
    "\n",
    "#         # Second-Level Item Embedding Combination\n",
    "#         self.item_fc2 = nn.Sequential(\n",
    "#             nn.Linear(2 * embedding_dim, 512),  # Concatenating two embedding sources\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(512, embedding_dim),\n",
    "#         )\n",
    "    \n",
    "#     def forward(self, user_ids, item1_ids, item2_ids, item_metadata):\n",
    "#         # User embedding and bias\n",
    "#         user_embed = self.user_embedding(user_ids)  # (batch, embedding_dim)\n",
    "#         user_bias = self.user_bias(user_ids)  # (batch, 1)\n",
    "\n",
    "#         # Item metadata-based embedding and bias\n",
    "#         item1_meta_embed = self.item_fc(item_metadata[item1_ids])  # (batch, embedding_dim)\n",
    "#         item2_meta_embed = self.item_fc(item_metadata[item2_ids])  # (batch, embedding_dim)\n",
    "\n",
    "#         item1_meta_bias = self.item_bias(item1_ids)  # (batch, 1)\n",
    "#         item2_meta_bias = self.item_bias(item2_ids)  # (batch, 1)\n",
    "\n",
    "#         # Item ID-based embedding (pretrained) and bias\n",
    "#         item1_id_embed = self.item_embedding(item1_ids)  # (batch, embedding_dim)\n",
    "#         item2_id_embed = self.item_embedding(item2_ids)  # (batch, embedding_dim)\n",
    "\n",
    "#         item1_id_bias = self.item_bias(item1_ids)  # (batch, 1)\n",
    "#         item2_id_bias = self.item_bias(item2_ids)  # (batch, 1)\n",
    "\n",
    "#         # Concatenate metadata-based and ID-based embeddings\n",
    "#         item1_combined = torch.cat([item1_meta_embed, item1_id_embed], dim=1)  # (batch, 2*embedding_dim)\n",
    "#         item2_combined = torch.cat([item2_meta_embed, item2_id_embed], dim=1)  # (batch, 2*embedding_dim)\n",
    "\n",
    "#         # Second-Level Representation Learning\n",
    "#         item1_embed_level2 = self.item_fc2(item1_combined)  # (batch, embedding_dim)\n",
    "#         item2_embed_level2 = self.item_fc2(item2_combined)  # (batch, embedding_dim)\n",
    "\n",
    "#         # Adding biases to the final embeddings (optional)\n",
    "#         item1_embed_level2 += item1_meta_bias + item1_id_bias  # (batch, embedding_dim)\n",
    "#         item2_embed_level2 += item2_meta_bias + item2_id_bias  # (batch, embedding_dim)\n",
    "#         user_embed += user_bias  # (batch, embedding_dim)\n",
    "\n",
    "#         return user_embed, item1_embed_level2, item2_embed_level2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddb7192-65de-4088-80f6-4b745215e7cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a0102ea4-3720-46ed-88b5-ce2759ca2f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_size = int(len(df) * VAL_SPLIT)\n",
    "# train_df, val_df = df[:-val_size], df[-val_size:] #= df[:-val_size], df[-val_size:]\n",
    "# # ======= Dataloaders =======\n",
    "# train_loader = DataLoader(PairwiseDataset(train_df), batch_size=BATCH_SIZE, shuffle=True)\n",
    "# val_loader = DataLoader(PairwiseDataset(val_df), batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "daeb6643-8b0e-47ab-bd71-5e8a51b14b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item1_id</th>\n",
       "      <th>item2_id</th>\n",
       "      <th>label</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13349</td>\n",
       "      <td>0</td>\n",
       "      <td>1349041740000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>22959</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1370958618000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>97562</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1440038761000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>23003</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1483320893000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>179127</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1600753653091</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8030471</th>\n",
       "      <td>1096899</td>\n",
       "      <td>26803</td>\n",
       "      <td>32852</td>\n",
       "      <td>32852</td>\n",
       "      <td>1692552324736</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8030472</th>\n",
       "      <td>1096899</td>\n",
       "      <td>177842</td>\n",
       "      <td>10643</td>\n",
       "      <td>10643</td>\n",
       "      <td>1692552357767</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8030473</th>\n",
       "      <td>1096900</td>\n",
       "      <td>183765</td>\n",
       "      <td>86867</td>\n",
       "      <td>183765</td>\n",
       "      <td>1600792118191</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8030474</th>\n",
       "      <td>1096900</td>\n",
       "      <td>155119</td>\n",
       "      <td>99585</td>\n",
       "      <td>155119</td>\n",
       "      <td>1615811081145</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8030475</th>\n",
       "      <td>1096900</td>\n",
       "      <td>25515</td>\n",
       "      <td>75800</td>\n",
       "      <td>25515</td>\n",
       "      <td>1693494834857</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8030476 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  item1_id  item2_id   label      timestamp  rating\n",
       "0              0         0     13349       0  1349041740000     5.0\n",
       "1              0     22959         1       1  1370958618000     1.0\n",
       "2              0     97562         2       2  1440038761000     5.0\n",
       "3              0     23003         3       3  1483320893000     3.0\n",
       "4              1    179127         5       5  1600753653091     5.0\n",
       "...          ...       ...       ...     ...            ...     ...\n",
       "8030471  1096899     26803     32852   32852  1692552324736     5.0\n",
       "8030472  1096899    177842     10643   10643  1692552357767     5.0\n",
       "8030473  1096900    183765     86867  183765  1600792118191     1.0\n",
       "8030474  1096900    155119     99585  155119  1615811081145     1.0\n",
       "8030475  1096900     25515     75800   25515  1693494834857     4.0\n",
       "\n",
       "[8030476 rows x 6 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "37c081fd-8f9c-47d5-ae38-e1601471d70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item1_id</th>\n",
       "      <th>item2_id</th>\n",
       "      <th>label</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>16177</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1490800837000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>174536</td>\n",
       "      <td>10</td>\n",
       "      <td>1676601720832</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>42860</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1588626339041</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>20877</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>1605455790941</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17870</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>1638039645551</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096896</th>\n",
       "      <td>1096896</td>\n",
       "      <td>197</td>\n",
       "      <td>11404</td>\n",
       "      <td>11404</td>\n",
       "      <td>1693892929945</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096897</th>\n",
       "      <td>1096897</td>\n",
       "      <td>32215</td>\n",
       "      <td>161020</td>\n",
       "      <td>161020</td>\n",
       "      <td>1617640776113</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096898</th>\n",
       "      <td>1096898</td>\n",
       "      <td>9974</td>\n",
       "      <td>33337</td>\n",
       "      <td>9974</td>\n",
       "      <td>1691348903005</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096899</th>\n",
       "      <td>1096899</td>\n",
       "      <td>45300</td>\n",
       "      <td>92761</td>\n",
       "      <td>92761</td>\n",
       "      <td>1692552496934</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096900</th>\n",
       "      <td>1096900</td>\n",
       "      <td>44042</td>\n",
       "      <td>76857</td>\n",
       "      <td>76857</td>\n",
       "      <td>1694098256216</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1096901 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  item1_id  item2_id   label      timestamp  rating\n",
       "0              0     16177         4       4  1490800837000     5.0\n",
       "1              1        10    174536      10  1676601720832     2.0\n",
       "2              2     42860        16      16  1588626339041     5.0\n",
       "3              3     20877        29      29  1605455790941     5.0\n",
       "4              4     17870        41      41  1638039645551     5.0\n",
       "...          ...       ...       ...     ...            ...     ...\n",
       "1096896  1096896       197     11404   11404  1693892929945     5.0\n",
       "1096897  1096897     32215    161020  161020  1617640776113     5.0\n",
       "1096898  1096898      9974     33337    9974  1691348903005     5.0\n",
       "1096899  1096899     45300     92761   92761  1692552496934     5.0\n",
       "1096900  1096900     44042     76857   76857  1694098256216     5.0\n",
       "\n",
       "[1096901 rows x 6 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "673ee0dc-f335-4f86-aacc-973e88c36937",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(PairwiseDataset(train), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(PairwiseDataset(val), batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f5e3d2c-88a2-4828-9451-b7478b9802fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = 1096901\n",
    "num_items = 198771\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f32256eb-7757-4659-8897-10d536899224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Training Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 15685/15685 [01:42<00:00, 153.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6931,Val Loss = 0.6931, Val Accuracy = 0.4991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 15685/15685 [01:41<00:00, 154.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss = 0.6928,Val Loss = 0.6935, Val Accuracy = 0.4997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 15685/15685 [01:41<00:00, 154.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss = 0.6855,Val Loss = 0.7002, Val Accuracy = 0.4995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 15685/15685 [01:42<00:00, 153.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss = 0.6699,Val Loss = 0.7147, Val Accuracy = 0.4995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 15685/15685 [01:41<00:00, 154.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss = 0.6537,Val Loss = 0.7300, Val Accuracy = 0.4994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 15685/15685 [01:41<00:00, 153.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss = 0.6401,Val Loss = 0.7449, Val Accuracy = 0.4994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 15685/15685 [01:42<00:00, 153.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss = 0.6289,Val Loss = 0.7578, Val Accuracy = 0.4993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 15685/15685 [01:42<00:00, 153.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss = 0.6196,Val Loss = 0.7687, Val Accuracy = 0.4993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 15685/15685 [01:41<00:00, 154.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss = 0.6113,Val Loss = 0.7797, Val Accuracy = 0.4995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 15685/15685 [01:41<00:00, 154.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss = 0.6034,Val Loss = 0.7908, Val Accuracy = 0.4995\n",
      "✅ Model Training Complete!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ======= Initialize Model, Loss, Optimizer =======\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TwoTowerModel(num_users, num_items, EMBEDDING_DIM, ITEM_FEATURE_DIM).to(device)\n",
    "criterion = BPRLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# ======= Training Loop =======\n",
    "# ======= Training & Validation =======\n",
    "log_file = \"warm_training_log.txt\"\n",
    "\n",
    "print(\"🚀 Training Model...\")\n",
    "with open(log_file, \"w\") as log:\n",
    "    log.write(\"🚀 Training Model...\\n\")\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "    \n",
    "        for user_ids, item1_ids, item2_ids,labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "            user_ids, item1_ids, item2_ids,labels = user_ids.to(device), item1_ids.to(device), item2_ids.to(device), labels.to(device)\n",
    "    \n",
    "            # Forward Pass\n",
    "            user_embed, item1_embed, item2_embed = model(user_ids, item1_ids, item2_ids)\n",
    "            #print(item1_embed==item2_embed)\n",
    "            # Compute Loss\n",
    "            # print(item1_embed==item2_embed)\n",
    "            loss = criterion(user_embed,item1_ids, item1_embed,item2_ids, item2_embed, labels)\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_loss = train_loss /len(train_loader)\n",
    "        # ======= Validation =======\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        val_loss = 0\n",
    "        for user_ids, item1_ids, item2_ids, labels in val_loader:\n",
    "            user_ids, item1_ids, item2_ids, labels = (\n",
    "                user_ids.to(device),\n",
    "                item1_ids.to(device),\n",
    "                item2_ids.to(device),\n",
    "                labels.to(device),\n",
    "            )\n",
    "            user_embed, item1_embed, item2_embed = model(user_ids, item1_ids, item2_ids)\n",
    "            #print((item1_embed==item2_embed).all())\n",
    "            score1 = (user_embed * item1_embed).sum(dim=1)  # Score for item1\n",
    "            score2 = (user_embed * item2_embed).sum(dim=1)  # Score for item2\n",
    "    \n",
    "            # Determine the correct positive and negative scores based on labels\n",
    "            labels_binary = (labels == item1_ids).float()\n",
    "            #print(labels_binary)\n",
    "            pos_scores = torch.where(labels_binary == 1, score1, score2)\n",
    "            neg_scores = torch.where(labels_binary == 1, score2, score1)\n",
    "            #print(pos_scores)\n",
    "            # Check if the model correctly ranked the positive item higher\n",
    "            loss = criterion(user_embed,item1_ids, item1_embed,item2_ids, item2_embed, labels)\n",
    "            val_loss += loss.item()\n",
    "            predictions = pos_scores > neg_scores\n",
    "    \n",
    "            correct += predictions.sum().item()\n",
    "            total += predictions.shape[0]\n",
    "    \n",
    "        val_accuracy = correct / total\n",
    "        val_loss=val_loss/len(val_loader)\n",
    "        print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f},Val Loss = {val_loss:.4f}, Val Accuracy = {val_accuracy:.4f}\")\n",
    "        log.write(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}, Val Accuracy = {val_accuracy:.4f}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# ======= Save Model =======\n",
    "#torch.save(model.state_dict(), \"trained_model.pth\")\n",
    "print(\"✅ Model Training Complete!\")\n",
    "with open(log_file, \"a\") as log:\n",
    "    log.write(\"✅ Model Training Complete!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e742fa9-0d42-49c8-ac01-1b5025e07a03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
