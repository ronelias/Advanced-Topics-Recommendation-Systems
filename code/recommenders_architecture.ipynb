{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cfe3e9a-c59d-4dd3-bfcf-a181ac4258ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "from scipy.sparse import load_npz\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import optuna\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a670bb0a-1661-4ee6-8580-b3f3e6001934",
   "metadata": {},
   "source": [
    "# Recommenders - MF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37d2a1c-7b55-4ead-a709-6d51617778bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFWithBiasesFreeze(nn.Module):\n",
    "    def __init__(self, df2, emb_dim, device):\n",
    "        super(MFWithBiasesFreeze, self).__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        # 1) Find total number of users/items\n",
    "        self.num_users = df2['user_idx'].max() + 1\n",
    "        self.num_items = df2['item_idx'].max() + 1\n",
    "        \n",
    "        # 2) Compute global mean rating\n",
    "        global_mean = df2['rating'].mean()\n",
    "        \n",
    "        # 3) user biases\n",
    "        user_means = df2.groupby('user_idx')['rating'].mean()\n",
    "        user_bias_series = user_means - global_mean            # shift by global_mean\n",
    "        # Reindex if needed to ensure we have a bias for every user_idx up to max()\n",
    "        user_bias_series = user_bias_series.reindex(range(self.num_users),fill_value=0.0)\n",
    "        \n",
    "        # 4) item biases\n",
    "        item_means = df2.groupby('item_idx')['rating'].mean()\n",
    "        item_bias_series = item_means - global_mean\n",
    "        item_bias_series = item_bias_series.reindex(range(self.num_items),fill_value=0.0)\n",
    "        \n",
    "        # Convert to torch Tensors for initialization\n",
    "        self.user_bias_init = torch.tensor(user_bias_series.values, dtype=torch.float32)\n",
    "        self.item_bias_init = torch.tensor(item_bias_series.values, dtype=torch.float32)\n",
    "        \n",
    "        # 5) Define model parameters\n",
    "        self.global_bias = nn.Parameter(torch.tensor([global_mean], dtype=torch.float32))\n",
    "        \n",
    "        self.user_bias = nn.Embedding(self.num_users, 1)\n",
    "        self.item_bias = nn.Embedding(self.num_items, 1)\n",
    "        \n",
    "        #    c) user and item embeddings\n",
    "        self.user_embedding = nn.Embedding(self.num_users, emb_dim)\n",
    "        self.item_embedding = nn.Embedding(self.num_items, emb_dim)\n",
    "        \n",
    "        # 6) Initialize everything\n",
    "        self._init_parameters()\n",
    "        \n",
    "        # 7) Move to device\n",
    "        self.to(self.device)\n",
    "\n",
    "\n",
    "    def _init_parameters(self): #Helper to initialize embeddings and biases from the precomputed stats\n",
    "\n",
    "        # a) user/item embeddings: small random Normal\n",
    "        nn.init.normal_(self.user_embedding.weight, std=0.01)\n",
    "        nn.init.normal_(self.item_embedding.weight, std=0.01)\n",
    "        \n",
    "        # b) user/item biases from data\n",
    "        with torch.no_grad():\n",
    "            self.user_bias.weight.copy_(self.user_bias_init.view(-1, 1))\n",
    "            self.item_bias.weight.copy_(self.item_bias_init.view(-1, 1))\n",
    "            \n",
    "        # c) Freeze biases\n",
    "        self.user_bias.weight.requires_grad = False\n",
    "        self.item_bias.weight.requires_grad = False\n",
    "        self.global_bias.requires_grad = False\n",
    "\n",
    "\n",
    "    def forward(self, user_idx, item_idx):\n",
    "        # 1) Retrieve bias terms\n",
    "        b_u = self.user_bias(user_idx).squeeze()  # shape: [batch_size]\n",
    "        b_i = self.item_bias(item_idx).squeeze()  # shape: [batch_size]\n",
    "        \n",
    "        # 2) Retrieve latent embeddings\n",
    "        u_emb = self.user_embedding(user_idx)      # shape: [batch_size, emb_dim]\n",
    "        i_emb = self.item_embedding(item_idx)      # shape: [batch_size, emb_dim]\n",
    "        \n",
    "        # 3) Dot product\n",
    "        dot = (u_emb * i_emb).sum(dim=1)\n",
    "        \n",
    "        # 4) Final rating\n",
    "        rating_pred = self.global_bias + b_u + b_i + dot\n",
    "\n",
    "        return rating_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38c0643-2eb4-4f5e-881f-a32e5619ce19",
   "metadata": {},
   "source": [
    "## Adding to the MFWithBiasesFreeze the encoded info about the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c16dfcb-aaa3-49e0-b7b1-25fcd6f0d11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFWithBiasesFreezeANDmetadata(nn.Module):\n",
    "    def __init__(self, df2, emb_dim, compressed_items_encodings, device):\n",
    "        super(MFWithBiasesFreezeANDmetadata, self).__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        # 1) Find total number of users/items\n",
    "        self.num_users = df2['user_idx'].max() + 1\n",
    "        self.num_items = df2['item_idx'].max() + 1\n",
    "        \n",
    "        # 2) Compute global mean rating\n",
    "        global_mean = df2['rating'].mean()\n",
    "        \n",
    "        # 3) user biases\n",
    "        user_means = df2.groupby('user_idx')['rating'].mean()\n",
    "        user_bias_series = user_means - global_mean            # shift by global_mean\n",
    "        # Reindex if needed to ensure we have a bias for every user_idx up to max()\n",
    "        user_bias_series = user_bias_series.reindex(range(self.num_users),fill_value=0.0)\n",
    "        \n",
    "        # 4) item biases\n",
    "        item_means = df2.groupby('item_idx')['rating'].mean()\n",
    "        item_bias_series = item_means - global_mean\n",
    "        item_bias_series = item_bias_series.reindex(range(self.num_items),fill_value=0.0)\n",
    "        \n",
    "        # Convert to torch Tensors for initialization\n",
    "        self.user_bias_init = torch.tensor(user_bias_series.values, dtype=torch.float32)\n",
    "        self.item_bias_init = torch.tensor(item_bias_series.values, dtype=torch.float32)\n",
    "        \n",
    "        # 5) Define model parameters\n",
    "        self.global_bias = nn.Parameter(torch.tensor([global_mean], dtype=torch.float32))\n",
    "        \n",
    "        self.user_bias = nn.Embedding(self.num_users, 1)\n",
    "        self.item_bias = nn.Embedding(self.num_items, 1)\n",
    "        \n",
    "        #    c) user and item embeddings\n",
    "        self.user_embedding = nn.Embedding(self.num_users, emb_dim)\n",
    "        self.item_embedding = nn.Embedding(self.num_items, emb_dim)\n",
    "\n",
    "        self.item_encodings = compressed_items_encodings  # {item_idx: encoding_vector}\n",
    "        encoding_dim = len(next(iter(compressed_items_encodings.values())))  # Get encoding size dynamically\n",
    "\n",
    "        # 6) Projection layer to transform concatenated item representation\n",
    "        self.item_proj = nn.Linear(encoding_dim + emb_dim, emb_dim)  # Project to emb_dim\n",
    "\n",
    "        # 6) Initialize everything\n",
    "        self._init_parameters()\n",
    "        \n",
    "        # 7) Move to device\n",
    "        self.to(self.device)\n",
    "\n",
    "\n",
    "    def _init_parameters(self): #Helper to initialize embeddings and biases from the precomputed stats\n",
    "\n",
    "        # a) user/item embeddings: small random Normal\n",
    "        nn.init.normal_(self.user_embedding.weight, std=0.01)\n",
    "        nn.init.normal_(self.item_embedding.weight, std=0.01)\n",
    "        \n",
    "        # b) user/item biases from data\n",
    "        with torch.no_grad():\n",
    "            self.user_bias.weight.copy_(self.user_bias_init.view(-1, 1))\n",
    "            self.item_bias.weight.copy_(self.item_bias_init.view(-1, 1))\n",
    "            \n",
    "        # c) Freeze biases\n",
    "        self.user_bias.weight.requires_grad = False\n",
    "        self.item_bias.weight.requires_grad = False\n",
    "        self.global_bias.requires_grad = False\n",
    "\n",
    "\n",
    "    def forward(self, user_idx, item_idx):\n",
    "        # 1) Retrieve bias terms\n",
    "        b_u = self.user_bias(user_idx).squeeze()  # shape: [batch_size]\n",
    "        b_i = self.item_bias(item_idx).squeeze()  # shape: [batch_size]\n",
    "        \n",
    "        # 2) Retrieve latent embeddings\n",
    "        u_emb = self.user_embedding(user_idx)      # shape: [batch_size, emb_dim]\n",
    "        i_emb = self.item_embedding(item_idx)      # shape: [batch_size, emb_dim]\n",
    "\n",
    "        # 3) Retrieve item encoding vector and concatenate with item embedding\n",
    "        batch_size = item_idx.shape[0]\n",
    "        item_vectors = torch.stack([torch.tensor(self.item_encodings.get(int(idx)),dtype=torch.float32, device=self.device)for idx in item_idx])  # Shape: [batch_size, encoding_dim]\n",
    "\n",
    "        combined_item_rep = torch.cat([i_emb, item_vectors], dim=1)  # Shape: [batch_size, emb_dim + encoding_dim]\n",
    "\n",
    "        # 4) Project concatenated vector back to emb_dim\n",
    "        i_emb_projected = self.item_proj(combined_item_rep)  # Shape: [batch_size, emb_dim]\n",
    "\n",
    "        # 5) Compute dot product with user embedding\n",
    "        dot = (u_emb * i_emb_projected).sum(dim=1)\n",
    "\n",
    "        # 6) Compute final predicted rating\n",
    "        rating_pred = self.global_bias + b_u + b_i + dot\n",
    "\n",
    "        return rating_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc56eb2-08da-482f-937c-1136a6cc3649",
   "metadata": {},
   "source": [
    "## Changed the name and added the clamp in the last row of the forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95596090-8787-49cf-ba50-efbebfb82447",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFWithBiasClamp(nn.Module):\n",
    "    def __init__(self, df2, emb_dim, device):\n",
    "        super(MFWithBiasClamp, self).__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        # 1) Find total number of users/items\n",
    "        self.num_users = df2['user_idx'].max() + 1\n",
    "        self.num_items = df2['item_idx'].max() + 1\n",
    "        \n",
    "        # 2) Compute global mean rating\n",
    "        global_mean = df2['rating'].mean()\n",
    "        \n",
    "        # 3) user biases\n",
    "        user_means = df2.groupby('user_idx')['rating'].mean()\n",
    "        user_bias_series = user_means - global_mean            # shift by global_mean\n",
    "        # Reindex if needed to ensure we have a bias for every user_idx up to max()\n",
    "        user_bias_series = user_bias_series.reindex(range(self.num_users),fill_value=0.0)\n",
    "        \n",
    "        # 4) item biases\n",
    "        item_means = df2.groupby('item_idx')['rating'].mean()\n",
    "        item_bias_series = item_means - global_mean\n",
    "        item_bias_series = item_bias_series.reindex(range(self.num_items),fill_value=0.0)\n",
    "        \n",
    "        # Convert to torch Tensors for initialization\n",
    "        self.user_bias_init = torch.tensor(user_bias_series.values, dtype=torch.float32)\n",
    "        self.item_bias_init = torch.tensor(item_bias_series.values, dtype=torch.float32)\n",
    "        \n",
    "        # 5) Define model parameters\n",
    "        self.global_bias = nn.Parameter(torch.tensor([global_mean], dtype=torch.float32))\n",
    "        \n",
    "        self.user_bias = nn.Embedding(self.num_users, 1)\n",
    "        self.item_bias = nn.Embedding(self.num_items, 1)\n",
    "        \n",
    "        #    c) user and item embeddings\n",
    "        self.user_embedding = nn.Embedding(self.num_users, emb_dim)\n",
    "        self.item_embedding = nn.Embedding(self.num_items, emb_dim)\n",
    "        \n",
    "        # 6) Initialize everything\n",
    "        self._init_parameters()\n",
    "        \n",
    "        # 7) Move to device\n",
    "        self.to(self.device)\n",
    "\n",
    "\n",
    "    def _init_parameters(self): #Helper to initialize embeddings and biases from the precomputed stats\n",
    "\n",
    "        # a) user/item embeddings: small random Normal\n",
    "        nn.init.normal_(self.user_embedding.weight, std=0.01)\n",
    "        nn.init.normal_(self.item_embedding.weight, std=0.01)\n",
    "        \n",
    "        # b) user/item biases from data\n",
    "        with torch.no_grad():\n",
    "            self.user_bias.weight.copy_(self.user_bias_init.view(-1, 1))\n",
    "            self.item_bias.weight.copy_(self.item_bias_init.view(-1, 1))\n",
    "\n",
    "\n",
    "    def forward(self, user_idx, item_idx):\n",
    "        # 1) Retrieve bias terms\n",
    "        b_u = self.user_bias(user_idx).squeeze()  # shape: [batch_size]\n",
    "        b_i = self.item_bias(item_idx).squeeze()  # shape: [batch_size]\n",
    "        \n",
    "        # 2) Retrieve latent embeddings\n",
    "        u_emb = self.user_embedding(user_idx)      # shape: [batch_size, emb_dim]\n",
    "        i_emb = self.item_embedding(item_idx)      # shape: [batch_size, emb_dim]\n",
    "        \n",
    "        # 3) Dot product\n",
    "        dot = (u_emb * i_emb).sum(dim=1)\n",
    "        \n",
    "        # 4) Final rating\n",
    "        rating_pred = self.global_bias + b_u + b_i + dot\n",
    "\n",
    "        #### ADD CLAMP ####\n",
    "        rating_pred = torch.clamp(rating_pred, min=1.0, max=5.0) #### ADD CLAMP ####\n",
    "\n",
    "        return rating_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0f4748-04c2-46ad-91e6-4a091bc2796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFNoItemEmbedding(nn.Module):\n",
    "    def __init__(self, df2, emb_dim, compressed_items_encodings, device):\n",
    "        super(MFNoItemEmbedding, self).__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        # 1) Find total number of users\n",
    "        self.num_users = df2['user_idx'].max() + 1\n",
    "        \n",
    "        # 2) Compute global mean rating\n",
    "        global_mean = df2['rating'].mean()\n",
    "        \n",
    "        # 3) Compute user biases\n",
    "        user_means = df2.groupby('user_idx')['rating'].mean()\n",
    "        user_bias_series = user_means - global_mean\n",
    "        user_bias_series = user_bias_series.reindex(range(self.num_users), fill_value=0.0)\n",
    "        \n",
    "        # 4) Compute item biases\n",
    "        item_means = df2.groupby('item_idx')['rating'].mean()\n",
    "        item_bias_series = item_means - global_mean\n",
    "        item_bias_series = item_bias_series.reindex(compressed_items_encodings.keys(), fill_value=0.0)\n",
    "        \n",
    "        # Convert biases to torch Tensors\n",
    "        self.user_bias_init = torch.tensor(user_bias_series.values, dtype=torch.float32)\n",
    "        self.item_bias_init = torch.tensor(item_bias_series.values, dtype=torch.float32)\n",
    "        \n",
    "        # 5) Define model parameters\n",
    "        self.global_bias = nn.Parameter(torch.tensor([global_mean], dtype=torch.float32))\n",
    "        \n",
    "        self.user_bias = nn.Embedding(self.num_users, 1)\n",
    "        self.item_bias = nn.Embedding(len(compressed_items_encodings), 1)  # Biases only for items\n",
    "        \n",
    "        # c) User embeddings (Items are fixed from precomputed encodings)\n",
    "        self.user_embedding = nn.Embedding(self.num_users, emb_dim)\n",
    "\n",
    "        # Use provided item encodings\n",
    "        self.item_encodings = compressed_items_encodings  \n",
    "        encoding_dim = len(next(iter(compressed_items_encodings.values())))\n",
    "\n",
    "        # 6) Projection layer to transform the item representation\n",
    "        self.item_proj = nn.Linear(encoding_dim, emb_dim)  # Project to emb_dim\n",
    "\n",
    "        # 7) Initialize everything\n",
    "        self._init_parameters()\n",
    "\n",
    "        # 8) Move to device\n",
    "        self.to(self.device)\n",
    "\n",
    "    def _init_parameters(self):\n",
    "        # a) User embeddings: small random Normal\n",
    "        nn.init.normal_(self.user_embedding.weight, std=0.01)\n",
    "        \n",
    "        # b) User/item biases from data\n",
    "        with torch.no_grad():\n",
    "            self.user_bias.weight.copy_(self.user_bias_init.view(-1, 1))\n",
    "            self.item_bias.weight.copy_(self.item_bias_init.view(-1, 1))\n",
    "\n",
    "        # c) Freeze biases\n",
    "        self.user_bias.weight.requires_grad = False\n",
    "        self.item_bias.weight.requires_grad = False\n",
    "        self.global_bias.requires_grad = False\n",
    "\n",
    "    def forward(self, user_idx, item_idx):\n",
    "        # 1) Retrieve bias terms\n",
    "        b_u = self.user_bias(user_idx).squeeze()  # [batch_size]\n",
    "        b_i = self.item_bias(item_idx).squeeze()  # [batch_size]\n",
    "\n",
    "        # 2) Retrieve user embedding\n",
    "        u_emb = self.user_embedding(user_idx)  # [batch_size, emb_dim]\n",
    "\n",
    "        # 3) Use precomputed item encodings directly\n",
    "        batch_size = item_idx.shape[0]\n",
    "        item_vectors = torch.stack([torch.tensor(self.item_encodings[int(idx)], dtype=torch.float32, device=self.device) for idx in item_idx])\n",
    "\n",
    "        # 4) Project item encoding back to emb_dim\n",
    "        i_emb_projected = self.item_proj(item_vectors)  # [batch_size, emb_dim]\n",
    "\n",
    "        # 5) Compute dot product with user embedding\n",
    "        dot = (u_emb * i_emb_projected).sum(dim=1)\n",
    "\n",
    "        # 6) Compute final predicted rating\n",
    "        rating_pred = self.global_bias + b_u + b_i + dot\n",
    "\n",
    "        return rating_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed25f30-b25d-47e2-90c0-20cd83c7e002",
   "metadata": {},
   "source": [
    "# Recommenders NCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4eaa0d-d1dc-4f6c-8edc-9ee397afcfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCFRecommender(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, hidden_units, dropout, alpha, df2):\n",
    "        super(NCFRecommender, self).__init__()\n",
    "        \n",
    "        # User and item embeddings for GMF & MLP\n",
    "        self.user_embedding_gmf = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding_gmf = nn.Embedding(num_items, embedding_dim)\n",
    "        \n",
    "        self.user_embedding_mlp = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding_mlp = nn.Embedding(num_items, embedding_dim)\n",
    "        \n",
    "        # GMF Layer (Element-wise multiplication)\n",
    "        self.gmf_layer = nn.Linear(embedding_dim, 1)\n",
    "        \n",
    "        # MLP Layers\n",
    "        layers = []\n",
    "        input_dim = embedding_dim * 2\n",
    "        for units in hidden_units:\n",
    "            layers.append(nn.Linear(input_dim, units))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            input_dim = units\n",
    "        \n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        \n",
    "        # Final fusion layer (combining GMF & MLP outputs)\n",
    "        self.final_layer = nn.Linear(hidden_units[-1] + 1, 1)\n",
    "        self.alpha = alpha  # Weighting factor for GMF and MLP\n",
    "        \n",
    "        # Load global, user, and item biases from the dataset\n",
    "        self.global_bias = df2['rating'].mean()\n",
    "        self.user_bias = torch.tensor(df2.groupby('user_idx')['rating'].mean() - self.global_bias, dtype=torch.float32)\n",
    "        self.item_bias = torch.tensor(df2.groupby('item_idx')['rating'].mean() - self.global_bias, dtype=torch.float32)\n",
    "        \n",
    "        # Ensure biases are frozen (not trainable)\n",
    "        self.user_bias = nn.Parameter(self.user_bias, requires_grad=False)\n",
    "        self.item_bias = nn.Parameter(self.item_bias, requires_grad=False)\n",
    "        \n",
    "    def forward(self, user_idx, item_idx):\n",
    "        # GMF forward pass\n",
    "        user_emb_gmf = self.user_embedding_gmf(user_idx)\n",
    "        item_emb_gmf = self.item_embedding_gmf(item_idx)\n",
    "        gmf_output = self.gmf_layer(user_emb_gmf * item_emb_gmf)\n",
    "        \n",
    "        # MLP forward pass\n",
    "        user_emb_mlp = self.user_embedding_mlp(user_idx)\n",
    "        item_emb_mlp = self.item_embedding_mlp(item_idx)\n",
    "        mlp_input = torch.cat([user_emb_mlp, item_emb_mlp], dim=-1)\n",
    "        mlp_output = self.mlp(mlp_input)\n",
    "        \n",
    "        # Concatenation of GMF & MLP outputs\n",
    "        final_input = torch.cat([gmf_output, mlp_output], dim=-1)\n",
    "        output = self.final_layer(final_input)\n",
    "        \n",
    "        # Add global, user, and item biases\n",
    "        output += self.global_bias + self.user_bias[user_idx].unsqueeze(1) + self.item_bias[item_idx].unsqueeze(1)\n",
    "\n",
    "        \n",
    "        # Ensure output is in range [0,5]\n",
    "        return torch.clamp(output, 0, 5).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7657f5f-b879-4ce5-8cb7-91503df79671",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCFRecommenderNoBias(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, hidden_units, dropout, alpha, df2):\n",
    "        super(NCFRecommenderNoBias, self).__init__()\n",
    "        \n",
    "        # User and item embeddings for GMF & MLP\n",
    "        self.user_embedding_gmf = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding_gmf = nn.Embedding(num_items, embedding_dim)\n",
    "        \n",
    "        self.user_embedding_mlp = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding_mlp = nn.Embedding(num_items, embedding_dim)\n",
    "        \n",
    "        # GMF Layer (Element-wise multiplication)\n",
    "        self.gmf_layer = nn.Linear(embedding_dim, 1)\n",
    "        \n",
    "        # MLP Layers\n",
    "        layers = []\n",
    "        input_dim = embedding_dim * 2\n",
    "        for units in hidden_units:\n",
    "            layers.append(nn.Linear(input_dim, units))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            input_dim = units\n",
    "        \n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        \n",
    "        # Final fusion layer (combining GMF & MLP outputs)\n",
    "        self.final_layer = nn.Linear(hidden_units[-1] + 1, 1)\n",
    "        self.alpha = alpha  # Weighting factor for GMF and MLP\n",
    "        \n",
    "    def forward(self, user_idx, item_idx):\n",
    "        # GMF forward pass\n",
    "        user_emb_gmf = self.user_embedding_gmf(user_idx)\n",
    "        item_emb_gmf = self.item_embedding_gmf(item_idx)\n",
    "        gmf_output = self.gmf_layer(user_emb_gmf * item_emb_gmf)\n",
    "        \n",
    "        # MLP forward pass\n",
    "        user_emb_mlp = self.user_embedding_mlp(user_idx)\n",
    "        item_emb_mlp = self.item_embedding_mlp(item_idx)\n",
    "        mlp_input = torch.cat([user_emb_mlp, item_emb_mlp], dim=-1)\n",
    "        mlp_output = self.mlp(mlp_input)\n",
    "        \n",
    "        # Concatenation of GMF & MLP outputs\n",
    "        final_input = torch.cat([gmf_output, mlp_output], dim=-1)\n",
    "        output = self.final_layer(final_input)\n",
    "\n",
    "        # Ensure output is in range [0,5]\n",
    "        return torch.clamp(output, 0, 5).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f7c40e-9bd9-477e-9063-d8eea4faa60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCFWithMetadata(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, hidden_units, dropout, alpha, df2, compressed_items_encodings, device):\n",
    "        super(NCFWithMetadata, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.compressed_items_encodings = compressed_items_encodings\n",
    "        encoding_dim = len(next(iter(compressed_items_encodings.values())))  # Get encoding size dynamically\n",
    "        \n",
    "        # User and item embeddings\n",
    "        self.user_embedding_gmf = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding_gmf = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "        self.user_embedding_mlp = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding_mlp = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "        # Projection layer to transform concatenated item representation\n",
    "        self.item_proj_gmf = nn.Linear(embedding_dim + encoding_dim, embedding_dim)\n",
    "        self.item_proj_mlp = nn.Linear(embedding_dim + encoding_dim, embedding_dim)\n",
    "\n",
    "        # GMF Layer (Element-wise multiplication)\n",
    "        self.gmf_layer = nn.Linear(embedding_dim, 1)\n",
    "\n",
    "        # MLP Layers\n",
    "        layers = []\n",
    "        input_dim = embedding_dim * 2\n",
    "        for units in hidden_units:\n",
    "            layers.append(nn.Linear(input_dim, units))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            input_dim = units\n",
    "\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "        # Final fusion layer (combining GMF & MLP outputs)\n",
    "        self.final_layer = nn.Linear(hidden_units[-1] + 1, 1)\n",
    "        self.alpha = alpha  # Weighting factor for GMF and MLP\n",
    "\n",
    "        # Load global, user, and item biases from the dataset\n",
    "        self.global_bias = df2['rating'].mean()\n",
    "        self.user_bias = torch.tensor(df2.groupby('user_idx')['rating'].mean() - self.global_bias, dtype=torch.float32)\n",
    "        self.item_bias = torch.tensor(df2.groupby('item_idx')['rating'].mean() - self.global_bias, dtype=torch.float32)\n",
    "\n",
    "        # Ensure biases are frozen (not trainable)\n",
    "        self.user_bias = nn.Parameter(self.user_bias, requires_grad=False)\n",
    "        self.item_bias = nn.Parameter(self.item_bias, requires_grad=False)\n",
    "\n",
    "        # Move to device\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, user_idx, item_idx):\n",
    "        # GMF forward pass\n",
    "        user_emb_gmf = self.user_embedding_gmf(user_idx)\n",
    "\n",
    "        # Retrieve item embedding\n",
    "        item_emb_gmf = self.item_embedding_gmf(item_idx)\n",
    "\n",
    "        # Retrieve item metadata encoding with default zero vector for cold items\n",
    "        item_metadata = torch.stack([\n",
    "            torch.tensor(self.compressed_items_encodings.get(int(idx), torch.zeros(len(next(iter(self.compressed_items_encodings.values()))))), \n",
    "                         dtype=torch.float32, device=self.device) \n",
    "            for idx in item_idx])\n",
    "\n",
    "        # Concatenate item embedding with metadata encoding\n",
    "        combined_item_rep_gmf = torch.cat([item_emb_gmf, item_metadata], dim=1)\n",
    "        combined_item_rep_mlp = torch.cat([self.item_embedding_mlp(item_idx), item_metadata], dim=1)\n",
    "\n",
    "        # Project back to embedding_dim\n",
    "        item_emb_gmf_projected = self.item_proj_gmf(combined_item_rep_gmf)\n",
    "        item_emb_mlp_projected = self.item_proj_mlp(combined_item_rep_mlp)\n",
    "\n",
    "        # Compute GMF output (Element-wise multiplication)\n",
    "        gmf_output = self.gmf_layer(user_emb_gmf * item_emb_gmf_projected)\n",
    "\n",
    "        # MLP forward pass\n",
    "        user_emb_mlp = self.user_embedding_mlp(user_idx)\n",
    "        mlp_input = torch.cat([user_emb_mlp, item_emb_mlp_projected], dim=-1)\n",
    "        mlp_output = self.mlp(mlp_input)\n",
    "\n",
    "        # Concatenation of GMF & MLP outputs\n",
    "        final_input = torch.cat([gmf_output, mlp_output], dim=-1)\n",
    "        output = self.final_layer(final_input)\n",
    "\n",
    "        # Retrieve user and item biases\n",
    "        user_bias = self.user_bias[user_idx].unsqueeze(1)\n",
    "\n",
    "        # Use `.get()` to safely handle cold items with missing biases\n",
    "        item_bias = torch.tensor([self.item_bias[idx].item() if idx < len(self.item_bias) else 0 \n",
    "                                  for idx in item_idx], dtype=torch.float32, device=self.device).unsqueeze(1)\n",
    "\n",
    "        # Add global, user, and item biases\n",
    "        output += self.global_bias + user_bias + item_bias\n",
    "\n",
    "        return torch.clamp(output, 0, 5).squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27355faf-9c58-462c-a7a3-8b1f64d0b854",
   "metadata": {},
   "source": [
    "## NCF for cold items - no items embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d151083-ff39-438a-81c1-49b33a57de30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCFNoItemEmbedding(nn.Module):\n",
    "    def __init__(self, num_users, embedding_dim, hidden_units, dropout, alpha, df2, compressed_items_encodings, device):\n",
    "        super(NCFNoItemEmbedding, self).__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        self.compressed_items_encodings = compressed_items_encodings\n",
    "        encoding_dim = len(next(iter(compressed_items_encodings.values())))  # Get encoding size dynamically\n",
    "        \n",
    "        # User embeddings for GMF & MLP\n",
    "        self.user_embedding_gmf = nn.Embedding(num_users, embedding_dim)\n",
    "        self.user_embedding_mlp = nn.Embedding(num_users, embedding_dim)\n",
    "        \n",
    "        # Projection layer to transform item encodings\n",
    "        self.item_proj_gmf = nn.Linear(encoding_dim, embedding_dim)\n",
    "        self.item_proj_mlp = nn.Linear(encoding_dim, embedding_dim)\n",
    "        \n",
    "        # GMF Layer (Element-wise multiplication)\n",
    "        self.gmf_layer = nn.Linear(embedding_dim, 1)\n",
    "        \n",
    "        # MLP Layers\n",
    "        layers = []\n",
    "        input_dim = embedding_dim * 2\n",
    "        for units in hidden_units:\n",
    "            layers.append(nn.Linear(input_dim, units))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            input_dim = units\n",
    "        \n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        \n",
    "        # Final fusion layer (combining GMF & MLP outputs)\n",
    "        self.final_layer = nn.Linear(hidden_units[-1] + 1, 1)\n",
    "        self.alpha = alpha  # Weighting factor for GMF and MLP\n",
    "        \n",
    "        # Load global, user, and item biases from the dataset\n",
    "        self.global_bias = df2['rating'].mean()\n",
    "        self.user_bias = torch.tensor(df2.groupby('user_idx')['rating'].mean() - self.global_bias, dtype=torch.float32)\n",
    "        self.item_bias = torch.tensor(df2.groupby('item_idx')['rating'].mean() - self.global_bias, dtype=torch.float32)\n",
    "        \n",
    "        # Ensure biases are frozen (not trainable)\n",
    "        self.user_bias = nn.Parameter(self.user_bias, requires_grad=False)\n",
    "        self.item_bias = nn.Parameter(self.item_bias, requires_grad=False)\n",
    "        \n",
    "        # Move to device\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, user_idx, item_idx):\n",
    "        # GMF forward pass\n",
    "        user_emb_gmf = self.user_embedding_gmf(user_idx)  # (batch_size, embedding_dim)\n",
    "\n",
    "        # Retrieve precomputed item encodings\n",
    "        item_encodings = torch.stack([\n",
    "            torch.tensor(self.compressed_items_encodings[int(idx)], dtype=torch.float32, device=self.device) for idx in item_idx\n",
    "        ])  # (batch_size, encoding_dim)\n",
    "\n",
    "        # Project item encodings to embedding_dim\n",
    "        item_emb_gmf = self.item_proj_gmf(item_encodings)  # (batch_size, embedding_dim)\n",
    "        gmf_output = self.gmf_layer(user_emb_gmf * item_emb_gmf)  # Element-wise multiplication\n",
    "        \n",
    "        # MLP forward pass\n",
    "        user_emb_mlp = self.user_embedding_mlp(user_idx)  # (batch_size, embedding_dim)\n",
    "        item_emb_mlp = self.item_proj_mlp(item_encodings)  # (batch_size, embedding_dim)\n",
    "        \n",
    "        mlp_input = torch.cat([user_emb_mlp, item_emb_mlp], dim=-1)  # (batch_size, 2 * embedding_dim)\n",
    "        mlp_output = self.mlp(mlp_input)\n",
    "        \n",
    "        # Concatenation of GMF & MLP outputs\n",
    "        final_input = torch.cat([gmf_output, mlp_output], dim=-1)\n",
    "        output = self.final_layer(final_input)\n",
    "        \n",
    "        # Retrieve user and item biases\n",
    "        user_bias = self.user_bias[user_idx].unsqueeze(1)\n",
    "    \n",
    "        # Use `.get()` to default missing item biases to zero\n",
    "        item_bias = torch.tensor([self.item_bias[idx].item() if idx < len(self.item_bias) else 0 \n",
    "                                  for idx in item_idx], dtype=torch.float32, device=self.device).unsqueeze(1)\n",
    "    \n",
    "        # Add global, user, and item biases\n",
    "        output += self.global_bias + user_bias + item_bias\n",
    "\n",
    "        # Ensure output is in range [0,5]\n",
    "        return torch.clamp(output, 0, 5).squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c743c1d5-7b92-43be-860b-6976e2000adc",
   "metadata": {},
   "source": [
    "# Pairwise Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b65325-4353-4235-a42c-6c2a3e6543cd",
   "metadata": {},
   "source": [
    "### Pairwise Warm - Experiment #1 Two Tower Model with Randomized Init "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad62497-3521-47d9-9d13-268a8a8147d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= Two-Tower Model (User & Item Networks) =======\n",
    "\n",
    "class TwoTowerModelRandomizedInit(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, item_metadata_dim):\n",
    "        super(TwoTowerModel, self).__init__()\n",
    "        \n",
    "        # User Tower (Embedding)\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim) \n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)  \n",
    "        # Item Tower (Using Item Metadata)\n",
    "        self.item_fc = nn.Sequential(\n",
    "            nn.Linear(item_metadata_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, embedding_dim),\n",
    "        )\n",
    "\n",
    "        # Second-Level Item Embedding Combination\n",
    "        self.item_fc2 = nn.Sequential(\n",
    "            nn.Linear(2 * embedding_dim, 512),  # Concatenating two embedding sources\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, embedding_dim),\n",
    "        )\n",
    "    \n",
    "    def forward(self, user_ids, item1_ids, item2_ids):\n",
    "        # User embedding\n",
    "        user_ids=user_ids.to(device)\n",
    "        item1_ids=item1_ids.to(device)\n",
    "        item2_ids=item2_ids.to(device)\n",
    "        user_embed = self.user_embedding(user_ids)  # (batch, embedding_dim)\n",
    "\n",
    "        # Item metadata-based embedding\n",
    "        item1_meta_embed = self.item_fc(item_metadata[item1_ids])  # (batch, embedding_dim)\n",
    "        item2_meta_embed = self.item_fc(item_metadata[item2_ids])  # (batch, embedding_dim)\n",
    "\n",
    "        # Item ID-based embedding (pretrained)\n",
    "        item1_id_embed = self.item_embedding(item1_ids)  # (batch, embedding_dim)\n",
    "        item2_id_embed = self.item_embedding(item2_ids)  # (batch, embedding_dim)\n",
    "\n",
    "        # Concatenate metadata-based and ID-based embeddings\n",
    "        item1_combined = torch.cat([item1_meta_embed, item1_id_embed], dim=1)  # (batch, 2*embedding_dim)\n",
    "        item2_combined = torch.cat([item2_meta_embed, item2_id_embed], dim=1)  # (batch, 2*embedding_dim)\n",
    "\n",
    "        # Second-Level Representation Learning\n",
    "        item1_embed_level2 = self.item_fc2(item1_combined)  # (batch, embedding_dim)\n",
    "        item2_embed_level2 = self.item_fc2(item2_combined)  # (batch, embedding_dim)\n",
    "\n",
    "        return user_embed, item1_embed_level2, item2_embed_level2\n",
    "\n",
    "\n",
    "\n",
    "class BPRLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BPRLoss, self).__init__()\n",
    "\n",
    "    def forward(self, user_embed, item1_ids, item1_embed, item2_ids, item2_embed, labels):\n",
    "        \"\"\"\n",
    "        Compute Bayesian Personalized Ranking (BPR) loss.\n",
    "\n",
    "        Args:\n",
    "        - user_embed: Tensor of shape (batch_size, embed_dim), user embeddings.\n",
    "        - item1_ids: Tensor of shape (batch_size,), IDs of item1.\n",
    "        - item1_embed: Tensor of shape (batch_size, embed_dim), embeddings for item1.\n",
    "        - item2_ids: Tensor of shape (batch_size,), IDs of item2.\n",
    "        - item2_embed: Tensor of shape (batch_size, embed_dim), embeddings for item2.\n",
    "        - labels: Tensor of shape (batch_size,), IDs of the correct (positive) item.\n",
    "\n",
    "        Returns:\n",
    "        - loss: Computed BPR loss.\n",
    "        \"\"\"\n",
    "        # Convert labels to binary: 1 if item1 is the positive item, else 0\n",
    "        labels_binary = (labels == item1_ids).float()\n",
    "\n",
    "        # Compute scores\n",
    "        score1 = (user_embed * item1_embed).sum(dim=1)  # Affinity score for item1\n",
    "        score2 = (user_embed * item2_embed).sum(dim=1)  # Affinity score for item2\n",
    "\n",
    "        # Assign correct positive and negative scores based on labels_binary\n",
    "        pos_score = torch.where(labels_binary == 1, score1, score2)\n",
    "        neg_score = torch.where(labels_binary == 1, score2, score1)\n",
    "\n",
    "        # Compute BPR loss\n",
    "        loss = -torch.log(torch.sigmoid(pos_score - neg_score)).mean()\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c018e7-3157-4c80-ae38-6a71122b863e",
   "metadata": {},
   "source": [
    "### Pairwise warm Experiment #2 Two Tower Model with previously trained by MF item and user embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acb3c94-2876-4629-b985-aefe39c2f1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= Two-Tower Model (User & Item Networks) =======\n",
    "\n",
    "class TwoTowerModelPrevEmbedInit(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, item_metadata_dim):\n",
    "        super(TwoTowerModel, self).__init__()\n",
    "        \n",
    "        # User Tower (Embedding)\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)  # LOAD PRETRAINED USER EMBEDDINGS\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)  # LOAD PRETRAINED ITEM EMBEDDINGS\n",
    "        self.user_embedding.weight.data.copy_(initial_user_embed.weight.data)\n",
    "        self.item_embedding.weight.data.copy_(initial_item_embed.weight.data)\n",
    "        # Item Tower (Using Item Metadata)\n",
    "        self.item_fc = nn.Sequential(\n",
    "            nn.Linear(item_metadata_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, embedding_dim),\n",
    "        )\n",
    "\n",
    "        # Second-Level Item Embedding Combination\n",
    "        self.item_fc2 = nn.Sequential(\n",
    "            nn.Linear(2 * embedding_dim, 512),  # Concatenating two embedding sources\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, embedding_dim),\n",
    "        )\n",
    "    \n",
    "    def forward(self, user_ids, item1_ids, item2_ids):\n",
    "        # User embedding\n",
    "        user_ids=user_ids.to(device)\n",
    "        item1_ids=item1_ids.to(device)\n",
    "        item2_ids=item2_ids.to(device)\n",
    "        user_embed = self.user_embedding(user_ids)  # (batch, embedding_dim)\n",
    "\n",
    "        # Item metadata-based embedding\n",
    "        item1_meta_embed = self.item_fc(item_metadata[item1_ids])  # (batch, embedding_dim)\n",
    "        item2_meta_embed = self.item_fc(item_metadata[item2_ids])  # (batch, embedding_dim)\n",
    "\n",
    "        # Item ID-based embedding (pretrained)\n",
    "        item1_id_embed = self.item_embedding(item1_ids)  # (batch, embedding_dim)\n",
    "        item2_id_embed = self.item_embedding(item2_ids)  # (batch, embedding_dim)\n",
    "\n",
    "        # Concatenate metadata-based and ID-based embeddings\n",
    "        item1_combined = torch.cat([item1_meta_embed, item1_id_embed], dim=1)  # (batch, 2*embedding_dim)\n",
    "        item2_combined = torch.cat([item2_meta_embed, item2_id_embed], dim=1)  # (batch, 2*embedding_dim)\n",
    "\n",
    "        # Second-Level Representation Learning\n",
    "        item1_embed_level2 = self.item_fc2(item1_combined)  # (batch, embedding_dim)\n",
    "        item2_embed_level2 = self.item_fc2(item2_combined)  # (batch, embedding_dim)\n",
    "\n",
    "        return user_embed, item1_embed_level2, item2_embed_level2\n",
    "\n",
    "\n",
    "\n",
    "class BPRLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BPRLoss, self).__init__()\n",
    "\n",
    "    def forward(self, user_embed, item1_ids, item1_embed, item2_ids, item2_embed, labels):\n",
    "        \"\"\"\n",
    "        Compute Bayesian Personalized Ranking (BPR) loss.\n",
    "\n",
    "        Args:\n",
    "        - user_embed: Tensor of shape (batch_size, embed_dim), user embeddings.\n",
    "        - item1_ids: Tensor of shape (batch_size,), IDs of item1.\n",
    "        - item1_embed: Tensor of shape (batch_size, embed_dim), embeddings for item1.\n",
    "        - item2_ids: Tensor of shape (batch_size,), IDs of item2.\n",
    "        - item2_embed: Tensor of shape (batch_size, embed_dim), embeddings for item2.\n",
    "        - labels: Tensor of shape (batch_size,), IDs of the correct (positive) item.\n",
    "\n",
    "        Returns:\n",
    "        - loss: Computed BPR loss.\n",
    "        \"\"\"\n",
    "        # Convert labels to binary: 1 if item1 is the positive item, else 0\n",
    "        labels_binary = (labels == item1_ids).float()\n",
    "\n",
    "        # Compute scores\n",
    "        score1 = (user_embed * item1_embed).sum(dim=1)  # Affinity score for item1\n",
    "        score2 = (user_embed * item2_embed).sum(dim=1)  # Affinity score for item2\n",
    "\n",
    "        # Assign correct positive and negative scores based on labels_binary\n",
    "        pos_score = torch.where(labels_binary == 1, score1, score2)\n",
    "        neg_score = torch.where(labels_binary == 1, score2, score1)\n",
    "\n",
    "        # Compute BPR loss\n",
    "        loss = -torch.log(torch.sigmoid(pos_score - neg_score)).mean()\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbba89f-26ee-4fc7-b762-20c6b722b368",
   "metadata": {},
   "source": [
    "### Pairwise warm - Experiment #3 Metadata to pretrained item embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14b3d8d-8e43-4e6d-8aaa-644254791b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetadataToEmbedding(nn.Module):\n",
    "    def __init__(self, input_size=3075, output_size=24, hidden_sizes=[512, 256]):\n",
    "        super(MetadataToEmbedding, self).__init__()\n",
    "        layers = []\n",
    "        sizes = [input_size] + hidden_sizes + [output_size]\n",
    "        for i in range(len(sizes) - 1):\n",
    "            layers.append(nn.Linear(sizes[i], sizes[i + 1]))\n",
    "            if i < len(sizes) - 2:\n",
    "                layers.append(nn.ReLU())\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def train_model(metadata, warm_item_embed, val_split=0.2, output_size=24, epochs=10, batch_size=64, lr=1e-3, hidden_sizes=[512, 256]):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Map item IDs to warm embeddings\n",
    "    warm_embeddings = warm_item_embed.weight.detach().to(device)\n",
    "\n",
    "    # Train-validation split\n",
    "    val_size = int(len(metadata) * val_split)\n",
    "    train_meta, val_meta = metadata[:-val_size], metadata[-val_size:]\n",
    "    train_emb, val_emb = warm_embeddings[:-val_size], warm_embeddings[-val_size:]\n",
    "\n",
    "    train_dataset = ItemDataset(train_meta, train_emb)\n",
    "    val_dataset = ItemDataset(val_meta, val_emb)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Model\n",
    "    model = MetadataToEmbedding(input_size=metadata.shape[1], output_size=output_size, hidden_sizes=hidden_sizes).to(device)\n",
    "\n",
    "    # Loss and Optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for meta, emb in train_loader:\n",
    "            meta, emb = meta.to(device), emb.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(meta)\n",
    "            loss = criterion(outputs, emb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for meta, emb in val_loader:\n",
    "                meta, emb = meta.to(device), emb.to(device)\n",
    "                outputs = model(meta)\n",
    "                val_loss += criterion(outputs, emb).item()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss / len(train_loader):.6f}, Val Loss: {val_loss / len(val_loader):.6f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"best_metadata_to_embedding.pth\")\n",
    "\n",
    "    print(\"Training complete. Best validation loss:\", best_val_loss)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdbbd8d-af89-4f8f-bccd-eeb75efbc5ee",
   "metadata": {},
   "source": [
    "### Pairwise Warm Experiment #4 in warm is using the model described as the NFC model above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e0464f-aa9d-4a1a-a665-eff15d7678b2",
   "metadata": {},
   "source": [
    "### Pairwise Cold Experiment #1 - Randomized weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28be8bca-9dfc-4096-9f03-2dedfb3add0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= Two-Tower Model (User & Item Networks) =======\n",
    "class TwoTowerModelPretrainedRandomInit(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, item_metadata_dim):\n",
    "        super(TwoTowerModel, self).__init__()\n",
    "        \n",
    "        # User Tower (Embedding)\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim) \n",
    " \n",
    "\n",
    "        \n",
    "        # Item Tower (Using Item Metadata)\n",
    "        self.item_fc = nn.Sequential(\n",
    "            nn.Linear(item_metadata_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, embedding_dim),\n",
    "        )\n",
    "    \n",
    "    def forward(self, user_ids, item1_ids, item2_ids):\n",
    "        item1_ids=item1_ids.to(device)\n",
    "        item2_ids=item2_ids.to(device)\n",
    "        user_embed = self.user_embedding(user_ids)  # (batch, embedding_dim)\n",
    "        item1_embed = self.item_fc(item_embeddings_tensor[item1_ids])  # (batch, embedding_dim)\n",
    "        item2_embed = self.item_fc(item_embeddings_tensor[item2_ids])  # (batch, embedding_dim)\n",
    "        \n",
    "        return user_embed, item1_embed, item2_embed\n",
    "\n",
    "# ======= Pairwise BPR Loss =======\n",
    "\n",
    "\n",
    "class BPRLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BPRLoss, self).__init__()\n",
    "\n",
    "    def forward(self, user_embed, item1_ids, item1_embed, item2_ids, item2_embed, labels):\n",
    "        \"\"\"\n",
    "        Compute Bayesian Personalized Ranking (BPR) loss.\n",
    "\n",
    "        Args:\n",
    "        - user_embed: Tensor of shape (batch_size, embed_dim), user embeddings.\n",
    "        - item1_ids: Tensor of shape (batch_size,), IDs of item1.\n",
    "        - item1_embed: Tensor of shape (batch_size, embed_dim), embeddings for item1.\n",
    "        - item2_ids: Tensor of shape (batch_size,), IDs of item2.\n",
    "        - item2_embed: Tensor of shape (batch_size, embed_dim), embeddings for item2.\n",
    "        - labels: Tensor of shape (batch_size,), IDs of the correct (positive) item.\n",
    "\n",
    "        Returns:\n",
    "        - loss: Computed BPR loss.\n",
    "        \"\"\"\n",
    "        # Convert labels to binary: 1 if item1 is the positive item, else 0\n",
    "        labels_binary = (labels == item1_ids).float()\n",
    "\n",
    "        # Compute scores\n",
    "        score1 = (user_embed * item1_embed).sum(dim=1)  # Affinity score for item1\n",
    "        score2 = (user_embed * item2_embed).sum(dim=1)  # Affinity score for item2\n",
    "\n",
    "        # Assign correct positive and negative scores based on labels_binary\n",
    "        pos_score = torch.where(labels_binary == 1, score1, score2)\n",
    "        neg_score = torch.where(labels_binary == 1, score2, score1)\n",
    "\n",
    "        # Compute BPR loss\n",
    "        loss = -torch.log(torch.sigmoid(pos_score - neg_score)).mean()\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0daf82-5fd8-4141-be17-48c5e8a35048",
   "metadata": {},
   "source": [
    "### Pairwise Cold Experiment #2 - pretrained on MF embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4294b1a1-d72c-462f-b6dc-a8a61cf2dd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= Two-Tower Model (User & Item Networks) =======\n",
    "class TwoTowerModelPretrainedUserEmbeddings(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, item_metadata_dim):\n",
    "        super(TwoTowerModel, self).__init__()\n",
    "        \n",
    "        # User Tower (Embedding)\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim) \n",
    "        ### LOAD PRETRAINED USER EMBEDDINGS\n",
    "        self.user_embedding.weight.data.copy_(initial_user_embed.weight.data)\n",
    "\n",
    "        \n",
    "        # Item Tower (Using Item Metadata)\n",
    "        self.item_fc = nn.Sequential(\n",
    "            nn.Linear(item_metadata_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, embedding_dim),\n",
    "        )\n",
    "    \n",
    "    def forward(self, user_ids, item1_ids, item2_ids):\n",
    "        item1_ids=item1_ids.to(device)\n",
    "        item2_ids=item2_ids.to(device)\n",
    "        user_embed = self.user_embedding(user_ids)  # (batch, embedding_dim)\n",
    "        item1_embed = self.item_fc(item_embeddings_tensor[item1_ids])  # (batch, embedding_dim)\n",
    "        item2_embed = self.item_fc(item_embeddings_tensor[item2_ids])  # (batch, embedding_dim)\n",
    "        \n",
    "        return user_embed, item1_embed, item2_embed\n",
    "\n",
    "# ======= Pairwise BPR Loss =======\n",
    "\n",
    "\n",
    "class BPRLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BPRLoss, self).__init__()\n",
    "\n",
    "    def forward(self, user_embed, item1_ids, item1_embed, item2_ids, item2_embed, labels):\n",
    "        \"\"\"\n",
    "        Compute Bayesian Personalized Ranking (BPR) loss.\n",
    "\n",
    "        Args:\n",
    "        - user_embed: Tensor of shape (batch_size, embed_dim), user embeddings.\n",
    "        - item1_ids: Tensor of shape (batch_size,), IDs of item1.\n",
    "        - item1_embed: Tensor of shape (batch_size, embed_dim), embeddings for item1.\n",
    "        - item2_ids: Tensor of shape (batch_size,), IDs of item2.\n",
    "        - item2_embed: Tensor of shape (batch_size, embed_dim), embeddings for item2.\n",
    "        - labels: Tensor of shape (batch_size,), IDs of the correct (positive) item.\n",
    "\n",
    "        Returns:\n",
    "        - loss: Computed BPR loss.\n",
    "        \"\"\"\n",
    "        # Convert labels to binary: 1 if item1 is the positive item, else 0\n",
    "        labels_binary = (labels == item1_ids).float()\n",
    "\n",
    "        # Compute scores\n",
    "        score1 = (user_embed * item1_embed).sum(dim=1)  # Affinity score for item1\n",
    "        score2 = (user_embed * item2_embed).sum(dim=1)  # Affinity score for item2\n",
    "\n",
    "        # Assign correct positive and negative scores based on labels_binary\n",
    "        pos_score = torch.where(labels_binary == 1, score1, score2)\n",
    "        neg_score = torch.where(labels_binary == 1, score2, score1)\n",
    "\n",
    "        # Compute BPR loss\n",
    "        loss = -torch.log(torch.sigmoid(pos_score - neg_score)).mean()\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438716b7-774f-49b1-93f9-984827f5d8d7",
   "metadata": {},
   "source": [
    "### Pairwise Cold Experiment #3 - Meta Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87faf8c-fbc8-4250-a586-ac8f544c43c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= Two-Tower Model (User & Item Networks) =======\n",
    "class TwoTowerModel(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, item_metadata_dim):\n",
    "        super(TwoTowerModel, self).__init__()\n",
    "        \n",
    "        # User Tower (Embedding)\n",
    "        self.user_fc = nn.Sequential(\n",
    "            nn.Linear(1027, 512),  # First reduce to 512 dimensions\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, embedding_dim),  # Then reduce to the desired embedding_dim (24)\n",
    "        )\n",
    "        # Item Tower (Using Item Metadata)\n",
    "        self.item_fc = nn.Sequential(\n",
    "            nn.Linear(item_metadata_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, embedding_dim),\n",
    "        )\n",
    "\n",
    "        \n",
    "    def forward(self, user_ids, item1_ids, item2_ids):\n",
    "        user_ids = user_ids.long().to(device)\n",
    "        \n",
    "        item1_ids=item1_ids.to(device)\n",
    "        item2_ids=item2_ids.to(device)\n",
    "        # User Tower: Compute user embeddings using user_fc (sequential)\n",
    "        user_embed = self.user_fc(user_embeddings[user_ids])  # (batch_size, embedding_dim)\n",
    "\n",
    "        item1_embed = self.item_fc(item_embeddings_tensor[item1_ids])  # (batch, embedding_dim)\n",
    "        item2_embed = self.item_fc(item_embeddings_tensor[item2_ids])  # (batch, embedding_dim)\n",
    "        \n",
    "        return user_embed, item1_embed, item2_embed\n",
    "\n",
    "# ======= Pairwise BPR Loss =======\n",
    "\n",
    "\n",
    "class BPRLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BPRLoss, self).__init__()\n",
    "\n",
    "    def forward(self, user_embed, item1_ids, item1_embed, item2_ids, item2_embed, labels):\n",
    "        \"\"\"\n",
    "        Compute Bayesian Personalized Ranking (BPR) loss.\n",
    "\n",
    "        Args:\n",
    "        - user_embed: Tensor of shape (batch_size, embed_dim), user embeddings.\n",
    "        - item1_ids: Tensor of shape (batch_size,), IDs of item1.\n",
    "        - item1_embed: Tensor of shape (batch_size, embed_dim), embeddings for item1.\n",
    "        - item2_ids: Tensor of shape (batch_size,), IDs of item2.\n",
    "        - item2_embed: Tensor of shape (batch_size, embed_dim), embeddings for item2.\n",
    "        - labels: Tensor of shape (batch_size,), IDs of the correct (positive) item.\n",
    "\n",
    "        Returns:\n",
    "        - loss: Computed BPR loss.\n",
    "        \"\"\"\n",
    "        # Convert labels to binary: 1 if item1 is the positive item, else 0\n",
    "        labels_binary = (labels == item1_ids).float()\n",
    "\n",
    "        # Compute scores\n",
    "        score1 = (user_embed * item1_embed).sum(dim=1)  # Affinity score for item1\n",
    "        score2 = (user_embed * item2_embed).sum(dim=1)  # Affinity score for item2\n",
    "\n",
    "        # Assign correct positive and negative scores based on labels_binary\n",
    "        pos_score = torch.where(labels_binary == 1, score1, score2)\n",
    "        neg_score = torch.where(labels_binary == 1, score2, score1)\n",
    "\n",
    "        # Compute BPR loss\n",
    "        loss = -F.logsigmoid(pos_score - neg_score).mean()\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c0b237-c2e5-4ee6-b85f-39068ff3cf11",
   "metadata": {},
   "source": [
    "### Pairwise cold - Experiment 4 - Bert features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5642c020-a672-4fd9-a2d1-30a9e1bdc690",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoTowerModelBertFeatures(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, item_metadata_dim):\n",
    "        super(TwoTowerModel, self).__init__()\n",
    "        \n",
    "        # User Tower (Processes item metadata of past interactions)\n",
    "        self.user_fc = nn.Sequential(\n",
    "            nn.Linear(item_metadata_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, embedding_dim),\n",
    "        )\n",
    "        # Item Tower (Processes item metadata)\n",
    "        self.item_fc = nn.Sequential(\n",
    "            nn.Linear(item_metadata_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, embedding_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, user_ids, item1_ids, item2_ids):\n",
    "        user_ids = user_ids.long().to(device)\n",
    "        item1_ids = item1_ids.to(device)\n",
    "        item2_ids = item2_ids.to(device)\n",
    "        \n",
    "        # Retrieve the precomputed interactions and mask for each user in the batch\n",
    "        batch_interactions = padded_user_interactions[user_ids]  # (batch_size, 256)\n",
    "        batch_mask = user_interaction_mask[user_ids]            # (batch_size, 256)\n",
    "        \n",
    "        # Replace padded indices (-1) with 0 (or any valid index) before lookup.\n",
    "        valid_batch_interactions = batch_interactions.clone()\n",
    "        valid_batch_interactions[valid_batch_interactions < 0] = 0\n",
    "        \n",
    "        # Gather item metadata for all interactions in the batch.\n",
    "        # item_embeddings_tensor has shape (num_items, item_metadata_dim)\n",
    "        batch_item_metadata = item_embeddings_tensor[valid_batch_interactions]  # (batch_size, 256, item_metadata_dim)\n",
    "        \n",
    "        # Process the metadata through the user tower.\n",
    "        processed = self.user_fc(batch_item_metadata)  # (batch_size, 256, embedding_dim)\n",
    "        \n",
    "        # Zero out padded positions using the mask.\n",
    "        batch_mask_expanded = batch_mask.unsqueeze(-1)  # (batch_size, 256, 1)\n",
    "        processed = processed * batch_mask_expanded\n",
    "        \n",
    "        # Compute the mean for valid interactions.\n",
    "        user_embed = processed.sum(dim=1) / (batch_mask.sum(dim=1, keepdim=True) + 1e-8)\n",
    "        \n",
    "        # Process item towers.\n",
    "        item1_embed = self.item_fc(item_embeddings_tensor[item1_ids])\n",
    "        item2_embed = self.item_fc(item_embeddings_tensor[item2_ids])\n",
    "        \n",
    "        return user_embed, item1_embed, item2_embed\n",
    "# ======= Pairwise BPR Loss =======\n",
    "\n",
    "\n",
    "class BPRLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BPRLoss, self).__init__()\n",
    "\n",
    "    def forward(self, user_embed, item1_ids, item1_embed, item2_ids, item2_embed, labels):\n",
    "        \"\"\"\n",
    "        Compute Bayesian Personalized Ranking (BPR) loss.\n",
    "\n",
    "        Args:\n",
    "        - user_embed: Tensor of shape (batch_size, embed_dim), user embeddings.\n",
    "        - item1_ids: Tensor of shape (batch_size,), IDs of item1.\n",
    "        - item1_embed: Tensor of shape (batch_size, embed_dim), embeddings for item1.\n",
    "        - item2_ids: Tensor of shape (batch_size,), IDs of item2.\n",
    "        - item2_embed: Tensor of shape (batch_size, embed_dim), embeddings for item2.\n",
    "        - labels: Tensor of shape (batch_size,), IDs of the correct (positive) item.\n",
    "\n",
    "        Returns:\n",
    "        - loss: Computed BPR loss.\n",
    "        \"\"\"\n",
    "        # Convert labels to binary: 1 if item1 is the positive item, else 0\n",
    "        labels_binary = (labels == item1_ids).float()\n",
    "\n",
    "        # Compute scores\n",
    "        score1 = (user_embed * item1_embed).sum(dim=1)  # Affinity score for item1\n",
    "        score2 = (user_embed * item2_embed).sum(dim=1)  # Affinity score for item2\n",
    "\n",
    "        # Assign correct positive and negative scores based on labels_binary\n",
    "        pos_score = torch.where(labels_binary == 1, score1, score2)\n",
    "        neg_score = torch.where(labels_binary == 1, score2, score1)\n",
    "\n",
    "        # Compute BPR loss\n",
    "        loss = -F.logsigmoid(pos_score - neg_score).mean()\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b29a15-cdfe-4422-bfac-14dc78c13b05",
   "metadata": {},
   "source": [
    "### Pairwise cold -  Experiment 5 - Bert features using similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f7ec5d-a04a-4a16-9497-952aec4d9cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoTowerModelBertFeaturesSimilarity(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, item_metadata_dim):\n",
    "        super(TwoTowerModel, self).__init__()\n",
    "        \n",
    "        # User Tower (Processes item metadata of past interactions)\n",
    "        self.user_fc = nn.Sequential(\n",
    "            nn.Linear(item_metadata_dim, 512),\n",
    "            nn.LeakyReLU(0.1),   # Changed activation to LeakyReLU\n",
    "            nn.Linear(512, embedding_dim),\n",
    "        )\n",
    "        # Item Tower (Processes item metadata)\n",
    "        self.item_fc = nn.Sequential(\n",
    "            nn.Linear(item_metadata_dim, 512),\n",
    "            nn.LeakyReLU(0.1),   # Changed activation to LeakyReLU\n",
    "            nn.Linear(512, embedding_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, user_ids, item1_ids, item2_ids):\n",
    "        user_ids = user_ids.long().to(device)\n",
    "        item1_ids = item1_ids.to(device)\n",
    "        item2_ids = item2_ids.to(device)\n",
    "        \n",
    "        # Retrieve precomputed interactions and mask for each user in the batch\n",
    "        batch_interactions = padded_user_interactions[user_ids]  # (batch_size, 256)\n",
    "        batch_mask = user_interaction_mask[user_ids]             # (batch_size, 256)\n",
    "        \n",
    "        # Create an exclusion mask: zero out positions where the history equals either candidate item.\n",
    "        exclusion_mask = (\n",
    "            (batch_interactions != item1_ids.unsqueeze(1)) &\n",
    "            (batch_interactions != item2_ids.unsqueeze(1))\n",
    "        ).float()  # shape: (batch_size, 256)\n",
    "        \n",
    "        # Combine the original mask with the exclusion mask.\n",
    "        adjusted_mask = batch_mask * exclusion_mask  # (batch_size, 256)\n",
    "        \n",
    "        # Replace padded indices (-1) with 0 (a safe index) before lookup.\n",
    "        valid_batch_interactions = batch_interactions.clone()\n",
    "        valid_batch_interactions[valid_batch_interactions < 0] = 0\n",
    "        \n",
    "        # Gather item metadata for all interactions in the batch.\n",
    "        batch_item_metadata = item_embeddings_tensor[valid_batch_interactions]  # (batch_size, 256, item_metadata_dim)\n",
    "        \n",
    "        # Process the user history through the user tower.\n",
    "        processed = self.user_fc(batch_item_metadata)  # (batch_size, 256, embedding_dim)\n",
    "        \n",
    "        # Zero out padded/filtered positions using adjusted_mask.\n",
    "        batch_mask_expanded = adjusted_mask.unsqueeze(-1)  # (batch_size, 256, 1)\n",
    "        processed = processed * batch_mask_expanded\n",
    "        \n",
    "        # Instead of averaging, compute cosine similarities between candidate items and each history embedding.\n",
    "        # Candidate 1:\n",
    "        item1_embed = self.item_fc(item_embeddings_tensor[item1_ids])  # (batch_size, embedding_dim)\n",
    "        sim1 = F.cosine_similarity(processed, item1_embed.unsqueeze(1), dim=2)  # (batch_size, 256)\n",
    "        user_score1 = sim1.max(dim=1).values  # (batch_size,)\n",
    "        \n",
    "        # Candidate 2:\n",
    "        item2_embed = self.item_fc(item_embeddings_tensor[item2_ids])\n",
    "        sim2 = F.cosine_similarity(processed, item2_embed.unsqueeze(1), dim=2)\n",
    "        user_score2 = sim2.max(dim=1).values  # (batch_size,)\n",
    "        \n",
    "        return user_score1, user_score2\n",
    "class BPRLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BPRLoss, self).__init__()\n",
    "\n",
    "    def forward(self, score1, score2, item1_ids, labels):\n",
    "        \"\"\"\n",
    "        Compute Bayesian Personalized Ranking (BPR) loss using candidate similarity scores.\n",
    "        \n",
    "        Args:\n",
    "        - score1: Tensor of shape (batch_size,), score for candidate item1.\n",
    "        - score2: Tensor of shape (batch_size,), score for candidate item2.\n",
    "        - item1_ids: Tensor of shape (batch_size,), IDs of candidate item1.\n",
    "        - labels: Tensor of shape (batch_size,), IDs of the correct (positive) item.\n",
    "        \n",
    "        Returns:\n",
    "        - loss: Computed BPR loss.\n",
    "        \"\"\"\n",
    "        # Create binary labels: 1 if candidate 1 is the positive item, else 0.\n",
    "        labels_binary = (labels == item1_ids).float()\n",
    "        \n",
    "        # Choose positive and negative scores based on the binary labels.\n",
    "        pos_score = torch.where(labels_binary == 1, score1, score2)\n",
    "        neg_score = torch.where(labels_binary == 1, score2, score1)\n",
    "        \n",
    "        # Compute BPR loss based on the difference between positive and negative scores.\n",
    "        loss = -F.logsigmoid(pos_score - neg_score).mean()\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c80a96e-c5a0-43ac-bcdc-fa13ea229669",
   "metadata": {},
   "source": [
    "# First models - were too computationaly expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56450cc9-b1d6-4b57-8d11-b8db1001543a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedMFModel(nn.Module):\n",
    "    def __init__(self, \n",
    "        image_embeddings, \n",
    "        title_embeddings, \n",
    "        embedding_dim, \n",
    "        num_users, \n",
    "        num_items,\n",
    "        device,\n",
    "        num_hidden_layers=2, \n",
    "        hidden_dim_list=None, \n",
    "        activation_fn=nn.ReLU,\n",
    "        dropout_rate=0.2,\n",
    "        batch_norm=False):\n",
    "        \n",
    "        super(AdvancedMFModel, self).__init__()\n",
    "        \n",
    "        self.device = device\n",
    "\n",
    "        # move to device\n",
    "        self.image_embeddings = {k: v.to(self.device) for k, v in image_embeddings.items()}\n",
    "        self.title_embeddings = {k: v.to(self.device) for k, v in title_embeddings.items()}\n",
    "        \n",
    "        self.user_embeddings = nn.Embedding(num_users, embedding_dim).to(self.device)         # Random user embeddings\n",
    "        self.item_embeddings = nn.Embedding(num_items, embedding_dim).to(self.device) # Random item embeddings for collaborative signal\n",
    "\n",
    "        if hidden_dim_list is None: # set  Default hidden dimensions if not provided\n",
    "            hidden_dim_list = [embedding_dim * 2] * num_hidden_layers\n",
    "\n",
    "        # Input dimension is the sum of random embeddings and metadata embeddings\n",
    "        input_dim = embedding_dim + list(next(iter(image_embeddings.values())).shape)[0] + list(next(iter(title_embeddings.values())).shape)[0]\n",
    "\n",
    "        # Dynamically build the FFN layers\n",
    "        layers = []\n",
    "        for i in range(num_hidden_layers):\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim_list[i]).to(self.device))\n",
    "            if batch_norm:\n",
    "                layers.append(nn.BatchNorm1d(hidden_dim_list[i]).to(self.device))\n",
    "            layers.append(activation_fn())\n",
    "            if dropout_rate > 0:\n",
    "                layers.append(nn.Dropout(dropout_rate))\n",
    "            input_dim = hidden_dim_list[i]\n",
    "        layers.append(nn.Linear(input_dim, embedding_dim).to(self.device)) # Add final layer to project to embedding_dim -  this way the number of nodes in the last layers dont need to be manually defined\n",
    "\n",
    "        self.ffn = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        user_ids = user_ids.to(self.device) # Move inputs to the correct device\n",
    "        \n",
    "        user_embeds = self.user_embeddings(user_ids).to(self.device) # Get User embeddings\n",
    "\n",
    "        # Metadata embeddings lookup\n",
    "        image_embeds = torch.stack([self.image_embeddings[int(item_id)] for item_id in item_ids]).to(self.device)\n",
    "        title_embeds = torch.stack([self.title_embeddings[int(item_id)] for item_id in item_ids]).to(self.device)\n",
    "\n",
    "        # Random collaborative item embeddings\n",
    "        item_collab_embeds = self.item_embeddings(item_ids.to(torch.long).to(self.device)).to(self.device)\n",
    "\n",
    "        # Concatenate random embeddings and metadata embeddings\n",
    "        combined_embeds = torch.cat((item_collab_embeds, image_embeds, title_embeds), dim=1)\n",
    "\n",
    "        # Feedforward network\n",
    "        final_item_embeds = self.ffn(combined_embeds)\n",
    "\n",
    "        # Compute dot product for recommendation scores\n",
    "        scores = (user_embeds * final_item_embeds).sum(dim=1)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5610273-4f7c-419a-8711-9a54775828ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedMFModel2(nn.Module):\n",
    "    def __init__(self, \n",
    "        image_embeddings, \n",
    "        title_embeddings, \n",
    "        embedding_dim, \n",
    "        num_users, \n",
    "        num_items,\n",
    "        device,\n",
    "        num_hidden_layers=2, \n",
    "        hidden_dim_list=None, \n",
    "        activation_fn=nn.ReLU,\n",
    "        dropout_rate=0.2,\n",
    "        batch_norm=False):\n",
    "        \n",
    "        super(AdvancedMFModel2, self).__init__()\n",
    "        \n",
    "        self.device = device\n",
    "\n",
    "        # move to device\n",
    "        self.image_embeddings = {k: v.to(self.device) for k, v in image_embeddings.items()}\n",
    "        self.title_embeddings = {k: v.to(self.device) for k, v in title_embeddings.items()}\n",
    "        \n",
    "        self.user_embeddings = nn.Embedding(num_users, embedding_dim).to(self.device) # Random user embeddings\n",
    "        nn.init.uniform_(self.user_embeddings.weight, 0, 0.5) # Initialize between 0 and 0.5 for convergence \n",
    "        self.item_embeddings = nn.Embedding(num_items, embedding_dim).to(self.device) # Random item embeddings for collaborative signal\n",
    "        nn.init.uniform_(self.item_embeddings.weight, 0, 0.5) # Initialize between 0 and 0.5 convergence\n",
    "        \n",
    "\n",
    "        if hidden_dim_list is None: # set  Default hidden dimensions if not provided\n",
    "            hidden_dim_list = [embedding_dim * 2] * num_hidden_layers\n",
    "\n",
    "        # Input dimension is the sum of random embeddings and metadata embeddings\n",
    "        input_dim = embedding_dim + list(next(iter(image_embeddings.values())).shape)[0] + list(next(iter(title_embeddings.values())).shape)[0]\n",
    "\n",
    "        # Dynamically build the FFN layers\n",
    "        layers = []\n",
    "        for i in range(num_hidden_layers):\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim_list[i]).to(self.device))\n",
    "            if batch_norm:\n",
    "                layers.append(nn.BatchNorm1d(hidden_dim_list[i]).to(self.device))\n",
    "            layers.append(activation_fn())\n",
    "            if dropout_rate > 0:\n",
    "                layers.append(nn.Dropout(dropout_rate))\n",
    "            input_dim = hidden_dim_list[i]\n",
    "        layers.append(nn.Linear(input_dim, embedding_dim).to(self.device)) # Add final layer to project to embedding_dim -  this way the number of nodes in the last layers dont need to be manually defined\n",
    "\n",
    "        self.ffn = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        user_ids = user_ids.to(self.device) # Move inputs to the correct device\n",
    "        \n",
    "        user_embeds = self.user_embeddings(user_ids).to(self.device) # Get User embeddings\n",
    "\n",
    "        # Metadata embeddings lookup\n",
    "        image_embeds = torch.stack([self.image_embeddings[int(item_id)] for item_id in item_ids]).to(self.device)\n",
    "        title_embeds = torch.stack([self.title_embeddings[int(item_id)] for item_id in item_ids]).to(self.device)\n",
    "\n",
    "        # Random collaborative item embeddings\n",
    "        item_collab_embeds = self.item_embeddings(item_ids.to(torch.long).to(self.device)).to(self.device)\n",
    "\n",
    "        # Concatenate random embeddings and metadata embeddings\n",
    "        combined_embeds = torch.cat((item_collab_embeds, image_embeds, title_embeds), dim=1)\n",
    "\n",
    "        # Feedforward network\n",
    "        final_item_embeds = self.ffn(combined_embeds)\n",
    "\n",
    "        # Compute dot product for recommendation scores\n",
    "        scores = (user_embeds * final_item_embeds).sum(dim=1)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7be9e54c-052c-4f98-a4dc-2cceff233e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassicMFModelWithSmartBias(nn.Module):\n",
    "    def __init__(self, \n",
    "                 df2: pd.DataFrame,\n",
    "                 num_users: int,\n",
    "                 num_items: int,\n",
    "                 embedding_dim: int,\n",
    "                 device: str):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.device = device\n",
    "\n",
    "        # 1) Compute overall mean rating\n",
    "        overall_mean = df2['rating'].mean()  # scalar float\n",
    "\n",
    "        # 2) Compute average rating per user and per item (grouped by user_idx, item_idx)\n",
    "        user_means = df2.groupby('user_idx')['rating'].mean()  # Series, index = user_idx\n",
    "        item_means = df2.groupby('item_idx')['rating'].mean()  # Series, index = item_idx\n",
    "\n",
    "        # Prepare bias initialization tensors\n",
    "        user_bias_init = torch.zeros(num_users, dtype=torch.float32)\n",
    "        item_bias_init = torch.zeros(num_items, dtype=torch.float32)\n",
    "        \n",
    "        # Fill in user bias init: (user_mean - overall_mean)\n",
    "        for u_idx, mean_val in user_means.items():\n",
    "            user_bias_init[u_idx] = mean_val - overall_mean\n",
    "        # Fill in item bias init: (item_mean - overall_mean)\n",
    "        for i_idx, mean_val in item_means.items():\n",
    "            item_bias_init[i_idx] = mean_val - overall_mean\n",
    "\n",
    "        # 3) Define Embeddings: user/item factors, user/item bias\n",
    "        self.user_factors = nn.Embedding(num_embeddings=num_users, embedding_dim=embedding_dim)\n",
    "        self.item_factors = nn.Embedding(num_embeddings=num_items, embedding_dim=embedding_dim)\n",
    "\n",
    "        # Each bias is an Embedding with dim=1\n",
    "        self.user_bias = nn.Embedding(num_embeddings=num_users, embedding_dim=1)\n",
    "        self.item_bias = nn.Embedding(num_embeddings=num_items, embedding_dim=1)\n",
    "\n",
    "        # 4) Set initial bias values to \"smart\" init\n",
    "        self.user_bias.weight.data = user_bias_init.unsqueeze(1)  # [num_users, 1]\n",
    "        self.item_bias.weight.data = item_bias_init.unsqueeze(1)  # [num_items, 1]\n",
    "\n",
    "        # 5) Global bias as a learnable parameter\n",
    "        self.global_bias = nn.Parameter(torch.tensor([overall_mean], dtype=torch.float32))\n",
    "\n",
    "        # 6) Optionally initialize user/item latent factors\n",
    "        # nn.init.normal_(self.user_factors.weight, mean=0.0, std=0.01)\n",
    "        # nn.init.normal_(self.item_factors.weight, mean=0.0, std=0.01)\n",
    "\n",
    "    def forward(self, user_ids: torch.LongTensor, item_ids: torch.LongTensor):\n",
    "\n",
    "        user_vecs = self.user_factors(user_ids)  # [batch_size, embedding_dim]\n",
    "        item_vecs = self.item_factors(item_ids)  # [batch_size, embedding_dim]\n",
    "\n",
    "        user_b = self.user_bias(user_ids).squeeze(dim=1)  # [batch_size]\n",
    "        item_b = self.item_bias(item_ids).squeeze(dim=1)  # [batch_size]\n",
    "        \n",
    "        dot = (user_vecs * item_vecs).sum(dim=1)          # [batch_size]\n",
    "\n",
    "        # 4) Combine all terms: global bias + user bias + item bias + dot\n",
    "        preds = self.global_bias + user_b + item_b + dot\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e6cccc-0ec1-4785-b759-f7bab2138749",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassicMFModelWithBias(nn.Module):\n",
    "    def __init__(self, \n",
    "                 df2: pd.DataFrame,\n",
    "                 num_users: int,\n",
    "                 num_items: int,\n",
    "                 embedding_dim: int,\n",
    "                 device: str):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.device = device\n",
    "\n",
    "        # 1) Compute overall mean rating\n",
    "        overall_mean = df2['rating'].mean()  # scalar float\n",
    "\n",
    "        # 3) Define Embeddings: user/item factors, user/item bias\n",
    "        self.user_factors = nn.Embedding(num_embeddings=num_users, embedding_dim=embedding_dim)\n",
    "        self.item_factors = nn.Embedding(num_embeddings=num_items, embedding_dim=embedding_dim)\n",
    "\n",
    "        # 5) Global bias as a learnable parameter\n",
    "        self.global_bias = nn.Parameter(torch.tensor([overall_mean], dtype=torch.float32))\n",
    "\n",
    "        # 6) Optionally initialize user/item latent factors\n",
    "        nn.init.normal_(self.user_factors.weight, mean=0.0, std=0.01)\n",
    "        nn.init.normal_(self.item_factors.weight, mean=0.0, std=0.01)\n",
    "\n",
    "    def forward(self, user_ids: torch.LongTensor, item_ids: torch.LongTensor):\n",
    "\n",
    "        user_vecs = self.user_factors(user_ids)  # [batch_size, embedding_dim]\n",
    "        item_vecs = self.item_factors(item_ids)  # [batch_size, embedding_dim]\n",
    "        \n",
    "        dot = (user_vecs * item_vecs).sum(dim=1)          # [batch_size]\n",
    "\n",
    "        preds = self.global_bias + dot\n",
    "        \n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de1f8c6-1db9-4906-876d-596e9a7c933d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassicMFModelWithSmartBiasClamp(nn.Module):\n",
    "    def __init__(self, \n",
    "                 df2: pd.DataFrame,\n",
    "                 num_users: int,\n",
    "                 num_items: int,\n",
    "                 embedding_dim: int = 32,\n",
    "                 device: str = 'cpu'):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.device = device\n",
    "\n",
    "        # 1) Compute overall mean rating\n",
    "        overall_mean = df2['rating'].mean()  # scalar float\n",
    "\n",
    "        # 2) Compute average rating per user and per item (grouped by user_idx, item_idx)\n",
    "        user_means = df2.groupby('user_idx')['rating'].mean()  # Series, index = user_idx\n",
    "        item_means = df2.groupby('item_idx')['rating'].mean()  # Series, index = item_idx\n",
    "\n",
    "        # Prepare bias initialization tensors\n",
    "        user_bias_init = torch.zeros(num_users, dtype=torch.float32)\n",
    "        item_bias_init = torch.zeros(num_items, dtype=torch.float32)\n",
    "        \n",
    "        # Fill in user bias init: (user_mean - overall_mean)\n",
    "        for u_idx, mean_val in user_means.items():\n",
    "            user_bias_init[u_idx] = mean_val - overall_mean\n",
    "        # Fill in item bias init: (item_mean - overall_mean)\n",
    "        for i_idx, mean_val in item_means.items():\n",
    "            item_bias_init[i_idx] = mean_val - overall_mean\n",
    "\n",
    "        # 3) Define Embeddings: user/item factors, user/item bias\n",
    "        self.user_factors = nn.Embedding(num_embeddings=num_users, embedding_dim=embedding_dim)\n",
    "        self.item_factors = nn.Embedding(num_embeddings=num_items, embedding_dim=embedding_dim)\n",
    "\n",
    "        # Each bias is an Embedding with dim=1\n",
    "        self.user_bias = nn.Embedding(num_embeddings=num_users, embedding_dim=1)\n",
    "        self.item_bias = nn.Embedding(num_embeddings=num_items, embedding_dim=1)\n",
    "\n",
    "        # 4) Set initial bias values to \"smart\" init\n",
    "        self.user_bias.weight.data = user_bias_init.unsqueeze(1)  # [num_users, 1]\n",
    "        self.item_bias.weight.data = item_bias_init.unsqueeze(1)  # [num_items, 1]\n",
    "\n",
    "        # 5) Global bias as a learnable parameter\n",
    "        self.global_bias = nn.Parameter(torch.tensor([overall_mean], dtype=torch.float32))\n",
    "\n",
    "        # 6) Optionally initialize user/item latent factors\n",
    "        # nn.init.normal_(self.user_factors.weight, mean=0.0, std=0.01)\n",
    "        # nn.init.normal_(self.item_factors.weight, mean=0.0, std=0.01)\n",
    "\n",
    "    def forward(self, user_ids: torch.LongTensor, item_ids: torch.LongTensor):\n",
    "\n",
    "        user_vecs = self.user_factors(user_ids)  # [batch_size, embedding_dim]\n",
    "        item_vecs = self.item_factors(item_ids)  # [batch_size, embedding_dim]\n",
    "\n",
    "        user_b = self.user_bias(user_ids).squeeze(dim=1)  # [batch_size]\n",
    "        item_b = self.item_bias(item_ids).squeeze(dim=1)  # [batch_size]\n",
    "        \n",
    "        dot = (user_vecs * item_vecs).sum(dim=1)          # [batch_size]\n",
    "\n",
    "        # 4) Combine all terms: global bias + user bias + item bias + dot\n",
    "        preds = self.global_bias + user_b + item_b + dot\n",
    "\n",
    "        # 5) Clamping to [1, 5]:\n",
    "        preds = torch.clamp(preds, min=1.0, max=5.0)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3944eb82-8198-4484-b71b-e339281bfcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class AdvancedMFModelTextEmbed(nn.Module):\n",
    "    def __init__(self, \n",
    "        image_embeddings, \n",
    "        text_embeddings, \n",
    "        embedding_dim, \n",
    "        num_users, \n",
    "        num_items,\n",
    "        device,\n",
    "        num_hidden_layers=2, \n",
    "        hidden_dim_list=None, \n",
    "        activation_fn=nn.ReLU,\n",
    "        dropout_rate=0.2,\n",
    "        batch_norm=False,\n",
    "        reduced_text_dim=128):  # New parameter for reduced text embedding dim\n",
    "        \n",
    "        super(AdvancedMFModelTextEmbed, self).__init__()\n",
    "        \n",
    "        self.device = device\n",
    "\n",
    "        # Move to device\n",
    "        self.image_embeddings = {k: v.to(self.device) for k, v in image_embeddings.items()}\n",
    "        self.text_embeddings = {k: v.to(self.device) for k, v in text_embeddings.items()}\n",
    "        \n",
    "        self.user_embeddings = nn.Embedding(num_users, embedding_dim).to(self.device) # Random user embeddings\n",
    "        nn.init.uniform_(self.user_embeddings.weight, 0, 0.5) # Initialize between 0 and 0.5 for convergence \n",
    "        self.item_embeddings = nn.Embedding(num_items, embedding_dim).to(self.device) # Random item embeddings\n",
    "        nn.init.uniform_(self.item_embeddings.weight, 0, 0.5) # Initialize between 0 and 0.5 for convergence\n",
    "\n",
    "        # Projection layer for text embeddings\n",
    "        self.text_projection = nn.Linear(1027, reduced_text_dim).to(self.device)\n",
    "\n",
    "        if hidden_dim_list is None:  # Default hidden dimensions if not provided\n",
    "            hidden_dim_list = [embedding_dim * 2] * num_hidden_layers\n",
    "\n",
    "        # Compute input dimension after projection\n",
    "        input_dim = embedding_dim + list(next(iter(image_embeddings.values())).shape)[0] + reduced_text_dim\n",
    "        print(f\"Input dim: {input_dim}\")\n",
    "\n",
    "        # Dynamically build the FFN layers\n",
    "        layers = []\n",
    "        for i in range(num_hidden_layers):\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim_list[i]).to(self.device))\n",
    "            if batch_norm:\n",
    "                layers.append(nn.BatchNorm1d(hidden_dim_list[i]).to(self.device))\n",
    "            layers.append(activation_fn())\n",
    "            if dropout_rate > 0:\n",
    "                layers.append(nn.Dropout(dropout_rate))\n",
    "            input_dim = hidden_dim_list[i]\n",
    "\n",
    "        layers.append(nn.Linear(input_dim, embedding_dim).to(self.device)) # Final layer\n",
    "\n",
    "        self.ffn = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        user_ids = user_ids.to(self.device) # Move inputs to the correct device\n",
    "        \n",
    "        user_embeds = self.user_embeddings(user_ids) # Get user embeddings\n",
    "\n",
    "        # Metadata embeddings lookup\n",
    "        image_embeds = torch.stack([self.image_embeddings[int(item_id)] for item_id in item_ids]).to(self.device)\n",
    "        text_embeds = torch.stack([self.text_embeddings[int(item_id)] for item_id in item_ids]).to(self.device)\n",
    "\n",
    "        # Apply the projection to reduce text embedding dimension\n",
    "        text_embeds = self.text_projection(text_embeds)\n",
    "\n",
    "        # Random collaborative item embeddings\n",
    "        item_collab_embeds = self.item_embeddings(item_ids.to(torch.long).to(self.device))\n",
    "\n",
    "        # Concatenate item embeddings and metadata embeddings\n",
    "        combined_embeds = torch.cat((item_collab_embeds, image_embeds, text_embeds), dim=1)\n",
    "\n",
    "        # Feedforward network\n",
    "        final_item_embeds = self.ffn(combined_embeds)\n",
    "\n",
    "        # Compute dot product for recommendation scores\n",
    "        scores = (user_embeds * final_item_embeds).sum(dim=1)\n",
    "\n",
    "        return scores\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
