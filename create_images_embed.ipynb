{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09065c86-92b1-4dd4-803d-56ba50218ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab89285-b942-426b-bcea-51bae10a18c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6b2378-afda-43d7-93dd-7d86a1714b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current directory\n",
    "current_dir = Path.cwd()\n",
    "\n",
    "encoded_dir = current_dir.parent / \"data\" / \"encoded\"\n",
    "images_dir = current_dir.parent / \"items_images\"\n",
    "pre_path = current_dir.parent / \"data\" / \"pre_process\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda6abfb-5902-4a52-9b09-d13a832986de",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = os.listdir(images_dir)\n",
    "len(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c114aa3-2e9c-405e-8ec1-d62838902dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the item_mapping\n",
    "with open(pre_path / 'item_mapping.pkl', 'rb') as f:\n",
    "    item_mapping = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aeb109-e40e-4a85-9dd2-4b73004027f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(item_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f86b701-4538-47fe-aab6-2b8fa48ae1a3",
   "metadata": {},
   "source": [
    "# Create the embeddings dict using ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61bcd59-2b01-4e03-abd9-c25a9ac9456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet50 model\n",
    "model = models.resnet50(pretrained=True)\n",
    "model = torch.nn.Sequential(*list(model.children())[:-1])  # Remove final classification layer\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc6e677-5497-4272-8862-4d6b45eedcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing transformations\n",
    "image_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to ResNet's input size\n",
    "    transforms.ToTensor(),          # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])  # Normalize as per ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d273bf40-b8ec-45b9-a9c1-345277208f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dictionary to store embeddings\n",
    "image_embeddings = {}\n",
    "\n",
    "i = 0\n",
    "# Process images\n",
    "for image_file in images_dir.iterdir():\n",
    "    if image_file.suffix.lower() in ['.jpg', '.png', '.jpeg']:  # Check for valid image extensions\n",
    "        try:\n",
    "            parent_asin = image_file.stem  # Extract parent_asin from the filename\n",
    "            item_idx = item_mapping.get(parent_asin)  # Map parent_asin to item_idx\n",
    "            image = Image.open(image_file).convert(\"RGB\")  # Ensure image is RGB\n",
    "            image_tensor = image_transforms(image).unsqueeze(0).to(device)  # Add batch dimension and move to GPU\n",
    "            with torch.no_grad():\n",
    "                embedding = model(image_tensor).squeeze().flatten()  # Extract embeddings and Flatten the output to a vector\n",
    "\n",
    "            image_embeddings[item_idx] = embedding  # Store the embedding with item_idx as the key\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_file.name}: {e}\")\n",
    "\n",
    "        i += 1\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Processed {i} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce179ea2-5df2-46c4-8322-6903817baf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1895a072-42e8-4d77-b272-0b63621b3c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all items are present in the image_embeddings dictionary\n",
    "embedding_size = 2048  # Size of the embedding\n",
    "for item_idx in range(len(item_mapping)):\n",
    "    if item_idx not in image_embeddings:\n",
    "        # Add a zero tensor for missing items\n",
    "        image_embeddings[item_idx] = torch.zeros(embedding_size).to(device)\n",
    "\n",
    "print(f\"Updated image_embeddings to contain all {len(item_mapping)} items.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429583ee-3ef9-457e-84f2-ddb92d1d1d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all tensors in image_embeddings are on the same device\n",
    "def check_tensors_device(tensor_dict):\n",
    "    devices = {tensor.device for tensor in tensor_dict.values()}\n",
    "    if len(devices) == 1:\n",
    "        print(f\"All tensors are on the same device: {devices.pop()}\")\n",
    "    else:\n",
    "        print(f\"Tensors are on multiple devices: {devices}\")\n",
    "\n",
    "# Example usage\n",
    "check_tensors_device(images_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7679800f-5529-4e18-b8e2-265d876b50ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move all tensors in image_embeddings to the \"cuda\" device\n",
    "def move_tensors_to_cuda(tensor_dict):\n",
    "    target_device = torch.device(\"cuda\")\n",
    "    for key, tensor in tensor_dict.items():\n",
    "        if tensor.device != target_device:\n",
    "            tensor_dict[key] = tensor.to(target_device)\n",
    "    print(f\"All tensors have been moved to {target_device}\")\n",
    "\n",
    "# Example usage\n",
    "move_tensors_to_cuda(images_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e5f672-37c6-43a3-bd48-be75fc5f2d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings dictionary\n",
    "output_file = encoded_dir / \"images_encodings.pkl\"\n",
    "with open(output_file, 'wb') as f:\n",
    "    pickle.dump(image_embeddings, f)\n",
    "\n",
    "print(f\"Image embeddings saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b842f623-5e3b-40f0-bd48-6406e2c50d2d",
   "metadata": {},
   "source": [
    "# Read the embeddings dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca44e24c-fe48-444e-830d-4dc2eec5c4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_images_file = encoded_dir / \"images_encodings.pkl\"\n",
    "\n",
    "with open(encoded_images_file, 'rb') as f:\n",
    "    images_embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90579db5-ad6e-4e62-94fa-70acb7469689",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838f0607-79b8-4da9-9e6c-1b2671d1a0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7159d3e-b79a-4034-a959-e5b17b7621c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ea4c13-c6bf-4f17-8ab6-7fc3550e9ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d61034f-a2b3-4558-92bc-aee1b73a9e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings dictionary\n",
    "output_file = encoded_dir / \"images_encodings.pkl\"\n",
    "with open(output_file, 'wb') as f:\n",
    "    pickle.dump(images_embeddings, f)\n",
    "\n",
    "print(f\"Image embeddings saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ae530b-1001-4687-ad4e-090eb93da387",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_images_file = encoded_dir / \"images_encodings.pkl\"\n",
    "\n",
    "with open(encoded_images_file, 'rb') as f:\n",
    "    images_embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2c068c-3d23-4c93-ab05-a89bc3008fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
